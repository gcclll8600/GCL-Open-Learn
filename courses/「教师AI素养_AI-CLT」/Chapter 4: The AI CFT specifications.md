## 第四章：《教师AI能力框架》细则

本章详细说明了针对十五个能力模块中每一个模块，教师培训或支持项目可以设计的课程目标和预期学习目标。这些目标通过教师应在各种情境下（包括在特定学科和/或跨学科教学实践中）执行的活动示例，得到了进一步阐释。

---

### 4.1 进阶水平1：掌握 (Acquire)

“掌握”水平的总体课程目标是支持所有教师达到教学专业在不同情境下所要求的基础AI能力或素养水平。以下的目标、学习目标和活动示例清晰地说明了每个能力模块所包含的内容：

**表2. 进阶水平1（掌握）的能力模块、目标与示例**

| **进阶水平1：掌握 (Acquire)** |
| :--- |
| **教师能力** | **课程目标 (CG)**<br>*(教师培训或支持项目应…)* | **学习目标 (LO)**<br>*(教师能够…)* | **情境化活动**<br>*(教师能够展现以下态度或行为上的改变)* |
| **以人为本的思维模式** |
| **1.1 人的能动性：**<br>教师审辨式地理解AI是由人主导的，AI创造者的企业和个人决策对人的自主性和权利有深远影响，并在评估和使用AI工具时，能意识到人的能动性的重要性。 | **CG1.1.1** 组织教师就AI提供的益处与削弱人的自主性和能动性的风险之间的两难困境进行讨论和表明立场，以培养对AI的审辨式思维；以具体的AI工具为例，支持教师审辨式地审视AI在本地教育情境中及其自身职责范围内的益处、局限性和风险。<br><br>**CG1.1.2** 展示AI系统生命周期中的关键步骤，引导教师理解创造者的企业和个人决策如何可能影响AI的作用。<br><br>**CG1.1.3** 强调过度依赖AI如何可能削弱思维能力和人的能动性。<br><br>**CG1.1.4** 提供编写基本提示的实践，以帮助在教育中使用AI时保护人的能动性，特别关注有特殊需求的学生。 | **LO1.1.1** 在其本地教育情境以及所教学科和年级中，审辨式地反思特定AI工具的益处、局限性和风险。<br><br>**LO1.1.2** 表现出对AI是由人主导的，以及AI创造者的企业和个人决策会影响其对人权、人的能动性、个人生活和社会作用的认识。<br><br>**LO1.1.3** 概述在AI开发的基本步骤中人的角色，从数据收集和处理，到AI系统的算法和功能设计，再到AI工具的部署和使用。<br><br>**LO1.1.4** 理解在AI系统设计和使用的关键步骤中采取基本措施保护人的能动性的必要性，通过确保尊重数据所有权、经同意收集数据、反偏见的数据标注和清洗、无歧视的AI算法，以及用户友好的功能和界面。 | **揭示AI的迷思：** 通过基本的风险效益分析，并强调人类在使用AI工具中的核心作用，审辨式地审视围绕具体AI工具的迷思。<br><br>**理解为何应禁用某些AI工具：** 基本理解为何某些AI工具因其可能削弱人的能动性和威胁人权而应被禁用。<br><br>**聚焦风险：** 列出某些AI工具可能削弱教师和学生能动性的潜在方式，例如，使用大型语言模型撰写论文的情况。<br><br>**了解基本的“应做”与“不应做”：** 编写日常提示，以在教学中使用AI时促进人的能动性，并鼓励学生在利用和评估AI时发挥能动性。 |
| **AI伦理** |
| **2.1 伦理原则：**<br>教师对围绕AI的伦理问题以及合乎道德的人机互动所需原则有基本了解，包括保护人权、人的能动性，促进语言和文化多样性、包容性及环境可持续性。 | **CG2.1.1** 通过对教育中AI工具使用案例的审辨式审视，揭示伦理争议。<br><br>**CG2.1.2** 通过审视与各项核心伦理原则相关的用例，促进对基本伦理原则的理解。引导教师理解为何这些原则至关重要，以及忽视它们可能如何造成伤害。这些原则概括为以下六个子主题：“不伤害”；相称性；不歧视；可持续性；人机互动中的人类决定权；以及透明度和可解释性。<br><br>**CG2.1.3** 通过本地、国家或国际关于AI伦理的法规示例，建立伦理原则与标准之间的联系；讨论其对个人的影响，并解释核心伦理原则如何在本地或国家监管框架中具体化。<br><br>**CG2.1.4** 倡导在使用AI中实现包容性，并引导教师讨论特定AI工具可能对包容和公平构成的风险，包括在教育情境中，并特别关注残障学习者和/或来自边缘化群体的学习者；引导教师讨论如何在个人层面减轻这些风险。 | **LO2.1.1** 从人的能动性、安全、隐私以及语言和文化相关性的角度，例举具体AI工具使用中的基本伦理争议。<br><br>**LO2.1.2** 解释核心伦理原则（如CG2.1.2所列），并通过个人选择和使用AI来内化这些原则。<br><br>**LO2.1.3** 将法规的关键条款与伦理原则相匹配，并理解其对教育的影响。<br><br>**LO2.1.4** 在教育中使用AI工具时，优先采取行动以最小化AI对公平和包容的负面影响，特别关注残障学生和/或来自边缘化群体的学生。 | **在伦理困境中进行“换位思考”：** 基于对AI在学校使用所带来的隐私、人的能动性、公平、包容、地方文化和语言以及气候变化等多重困境的理解，对AI的使用采取伦理视角。<br><br>**伦理原则的知识图谱绘制：** 应用基础知识图谱工具（如纸质工作表或数字概念图应用），将不同核心原则、对相关争议的回应、其与法规的对应关系以及在学校使用的AI工具示例之间的联系可视化。<br><br>**对本地法规的个人观察：** 观察本地AI法规是否跟上AI技术的迭代步伐，并通过将其与伦理原则和本地情境相匹配来评估适用法规。<br><br>**AI工具的偏见：** 警惕在学校使用的AI工具的偏见及其可能排斥或边缘化残障人士和来自弱势群体的学生的风险；向机构管理者或负责机构报告风险。 |
| **AI基础与应用** |
| **3.1 基础AI技术与应用：**<br>期望教师掌握关于AI的基础概念知识，包括：AI的定义，关于AI模型如何训练的基础知识及相关的数据和算法知识；AI技术的主要类别及各自的例子；以及审视特定AI工具对教育的适宜性并操作已验证AI工具的能力。 | **CG3.1.1** 根据教师的职责和以往的AI经验，调整AI基础概念知识的难度；阐释特定AI工具是如何基于数据和算法开发的；并解释AI工具用于处理数据以生成其输出的基本方法。<br><br>**CG3.1.2** 支持教师亲手操作与其职责相关的AI工具，使其对这些工具的工作原理有基本了解；引导他们体验不同类型的AI工具，帮助他们理解AI相较于前几代ICT工具的技术进步，以及不同类别AI工具的功能特性。<br><br>**CG3.1.3** 通过引入一种用于分析特定AI工具对本地情境的可靠性和适宜性的初步方法，并让教师参与试用该方法，来支持用户测试AI工具。<br><br>**CG3.1.4** 支持教师建立自己的AI工具集，从推荐基础示例工具开始，引导他们根据自身需求和本地情境，特别考虑开源工具，来策展可信赖的AI。 | **LO3.1.1** 展示与其能力和职责相适应的概念知识，了解AI系统如何使用数据、算法和计算架构进行开发；掌握关于数据、算法和编程的相关理解和技能；并例举包括问题界定、设计、训练、测试、部署、反馈和迭代在内的关键步骤。<br><br>**LO3.1.2** 例举什么是AI、什么不是AI，AI技术的主要类别，AI相较于前几代ICT工具可能实现的新能力，以及各类AI工具的核心功能。<br><br>**LO3.1.3** 在本地情境中，定位并操作其日常工作所必需的AI工具。<br><br>**LO3.1.4** 解释评估AI工具以确保其可及性、包容性和可靠性的重要性；对特定AI工具在本地情境下对教育的适宜性进行基本分析，特别关注对有特殊需求学生的影响。<br><br>**LO3.1.5** 开始整合一个个人可信赖的AI工具集，这些工具对生活和工作是必需的，并与本地语言和文化相关。调查本地相关的开源AI工具的可用程度。 | **AI工作原理的概念图绘制：** 开始绘制并迭代更新纸质或数字概念图，展示AI系统是如何开发的，以及教育中使用的特定AI工具的决策工作流程。<br><br>**技能的扩展与增强：** 扩展与教师职责相关的AI工具知识。帮助他们增强现有操作技能的流畅度和广度，或发展新技能。<br><br>**选择AI工具的“导航罗盘”：** 辨别哪些工具正在使用AI，哪些没有，以及在本地情境中使用的ICT工具和AI工具的基本比较优势和局限性。<br><br>**收集合适的AI工具：** 与其他教师和学校管理者合作，评估AI提供商正在使用或推荐的特定工具的适宜性，并讨论是否应采用；收集已验证的AI工具，分享开源工具，并开始策展一个可信赖的AI工具集。 |

好的，这是该章节内容的标准翻译，已为您整理为Markdown格式。

### **4.2 进阶水平2：深化 (Deepen)**

“深化”水平的总体课程目标是支持教师成为在使用AI方面的**完全胜任的教师**或**骨干教师**。他们应在其分析和决策中展现以人为本的视角、合乎道德的行为、对AI的深化概念理解，以及应用AI支持教学活动和专业学习的能力。以下的目标、学习目标和活动示例具体说明了可以涵盖哪些基本主题、如何组织培训，以及教师在达成每个能力模块后可能展现的行为。

**表3. 进阶水平2（深化）的能力模块、目标与示例**

| **深化 (Deepen)** |
| :--- |
| **教师能力** | **课程目标 (CG)**\<br\>*(教师培训或支持项目应…)* | **学习目标 (LO)**\<br\>*(教师能够…)* | **情境化活动**\<br\>*(教师能够展现以下态度或行为上的改变)* |
| **以人为本的思维模式** |
| **1.2 由人负责：**\<br\>教师能展示出对在恰当部署和使用AI中由人负责和人来决定的深刻理解，以及评估AI在辅助人机决策循环中能力、和评估在教育中用AI替代人类做出高风险决策的过度宣传主张的审辨能力。 | **CG1.2.1** 通过审视在教育管理、评估、教学策略和学生与AI互动中使用AI进行决策循环的用例，深化教师对缺乏由人负责相关风险的理解，丰富并巩固他们关于“由人负责”作为AI整个生命周期核心部分重要性的观点。\<br\>\<br\>**CG1.2.2** 通过鼓励教师辩论在AI辅助的决策循环中应由人还是AI负责，来培养“由人负责”是一项法律义务的理解；引导教师审阅本地和国际监管框架如何界定AI设计和提供AI服务（包括教育领域）中由人负责的原则。\<br\>\<br\>**CG1.2.3** 通过强调教师不断变化的角色和责任，建立由人负责与教师权利之间的联系，同时强调教师的核心角色是不可替代的，其问责和自主权不能被AI侵占；支持教师审阅本地政策是否在AI时代保护了教师的权利和问责。\<br\>\<br\>**CG1.2.4** 通过鼓励教师审视特定AI工具的可解释性局限（如AI无法理解真实世界或进行价值判断）以及当前一代AI工具中无法解释的幻觉、不正确答案和事实歪曲，来揭示缺乏用户问责的相关风险；讨论AI对学生学习构成的风险，特别是对有特殊需求的学生（削弱他们的智力发展、审辨思维能力、人际互动、知识建构以及形成和表达独立意见的能力）。 | **LO1.2.1** 理解在人机决策循环中由人负责是一项法律义务。\<br\>\<br\>**LO1.2.2** 应用本地和/或国际监管框架，审视特定AI工具的设计或使用是否削弱了由人负责的原则。\<br\>\<br\>**LO1.2.3** 参考国际或本地政策，捍卫教师在教育中使用AI的问责，并表现出对使用AI的输出和预测来侵占人类教师的决策以及学生的思维过程、知识建构和自我表达的抵制。\<br\>\<br\>**LO1.2.4** 在决策循环中展示教师的问责，包括在确定AI工具在教学中的适宜性、设计适合年龄的教学方法论以及提供必要的人际互动以鼓励自主学习过程，并为有特殊需求者提供特定支持时。 | **AI辅助决策循环中的由人负责是一项法律义务：** 绘制一份关键责任承担者及其在教育中设计、部署和使用AI中角色的概念图，并界定他们由人负责的责任。\<br\>\<br\>**教师的问责和权利不能被AI侵占：** 起草一份报告，说明在教育中采用AI时，能够保护教师权利和问责的最相关法规、负责机构和程序。\<br\>\<br\>**教师的问责是在教育中合乎道德且有效使用AI的人为保障：** 绘制一份概念图，说明教师在验证和选择合适的AI工具、设计教学方法论、驱动人际互动、引导学生使用AI以及支持不同能力学生方面可以扮演的可行角色。 |
| **AI伦理** |
| **2.2 安全负责地使用：**\<br\>期望教师能够内化安全负责使用AI的基本伦理规则，包括尊重数据隐私、知识产权和其他法律框架；并习惯性地将这些伦理观融入到对教育中AI工具、数据和AI生成内容的评估与利用中。 | **CG2.2.1** 通过分析关于典型AI安全风险或常见AI安全事件的案例场景，从两个维度深化教师对设计和使用阶段AI安全主要威胁的理解：一个维度涵盖“设计即安全”和“使用即安全”，另一个维度涵盖机构和个人的AI安全。\<br\>\<br\>**CG2.2.2** 促进对使用AI时典型法律义务及其违规后果的分析——这包括禁止未经同意使用受版权保护内容、通过泄露个人数据侵犯隐私、散布虚假或错误信息、宣扬仇恨言论，以及从事针对残障人士或弱势群体的AI放大的网络歧视或欺凌的法律；引导教师讨论案例研究，以深化他们对不负责任使用AI的社会和法律后果的理解。\<br\>\<br\>**CG2.2.3** 支持教师建立遵守安全负责使用AI的法规与其本地情境和工作职责之间的联系；支持教师搜索并找到与本地情境相关的国际法规示例；并组织教师通过将国际法规调整以适应其特定情境，亲手起草其所在机构、教室和/或个人的安全负责使用AI的规则。 | **LO2.2.1** 解释在机构和个人层面与AI安全相关的典型问题，并展示对AI安全背后各种原因的深刻理解，包括：“设计即安全”、“使用即安全”、数据所有权、数据主权、数据隐私、拒绝为获取AI服务而放弃个人隐私的权利、避免为提示AI输出而泄露详细个人数据，以及防止数据偏见和算法偏见。\<br\>\<br\>**LO2.2.2** 展示对本地适用的保护数据隐私和确保AI安全的法规的熟悉；审视特定AI工具在教育中的潜在伦理风险，并提出缓解策略。\<br\>\<br\>**LO2.2.3** 实施措施以保障教师自身及其学生的数据隐私，确保其数据的收集、使用、分享、存档和删除均获得同意；意识到隐藏的风险，特别是对有特殊需求的学生。\<br\>\<br\>**LO2.2.4** 应用指导方针以确保教师和学生负责任地使用AI，遵守伦理原则，例如：尊重他人版权并保护自己的版权、减轻偏见、打击深度伪造和AI放大的仇恨言论，以及保护自己和学生，特别是残障学生，免受AI操纵的欺凌和歧视。 | **个人AI安全追踪器：** 基于案例研究，绘制并更新一份关于典型AI安全问题和常见事件及其主要原因的概念图；对机构和个人，特别是残障人士的可能威胁；以及在学校和个人层面的缓解措施。\<br\>\<br\>**将个人教育AI工具集白名单化：** 审视其个人AI工具集的安全性，考察每个工具的所有者、设计伦理、数据来源、算法、包容性可及性和功能选择，以揭示其潜在目的、偏见和风险水平。与同事和学校管理者合作，改进AI工具的伦理评估方法。\<br\>\<br\>**迭代更新“应做”与“不应做”清单：** 观察并评估学校中高风险和不负责任使用AI的案例，并迭代更新教师和学生的“应做”与“不应做”清单；向学生解释负责任使用AI的相关伦理和法律原则以及违反本地或国际法规的个人后果。 |
| **AI基础与应用** |
| **3.2 应用技能：**\<br\>期望教师能够熟练操作在教育环境中采用的AI工具；深化其对各类AI技术的知识以及关于数据和算法的实践技能，这些知识和技能需与教学职责和背景能力相适应，同时在实践中融入相关的伦理原则。 | **CG3.2.1** 丰富典型AI工具的“操作与比较”经验，支持教师获得主要功能的经验并学习这些工具的操作技能；引导他们分析常见AI技术（如符号型、预测型和生成式AI）的异同及其对教育的影响。\<br\>\<br\>**CG3.2.2** 通过促进教师基于研究的学习，包括关于选定的AI系统（如大型语言模型）如何被训练和测试，以及训练使用了哪些典型模型、算法和数据集，来为深化概念知识的建构提供支架。\<br\>\<br\>**CG3.2.3** 支持在数据、算法和编码方面基于问题的操作技能学习。根据教师的先验知识和工作职责，设计典型的问题情境，以促进教师获取关于数据、算法和编码的知识与操作技能，以及他们使用这些技能设计AI应用的能力。\<br\>\<br\>**CG3.2.4** 提供评估AI工具“设计即伦理”的实践操作。组织教师审阅和修改一套特定的标准或工具，用于评估“设计即伦理”的关键方面；并促进教师使用调整后的标准或工具来评估选定的AI工具，涉及数据安全、数据隐私、用户安全、对不同能力人群的可及性、数据和算法中的偏见（包括性别歧视）以及对弱势群体的潜在伤害等。 | **LO3.2.1** 熟练操作日常生活中和教育中常用的AI工具；例举这些工具使用的典型技术，并解释其对教育的影响。\<br\>\<br\>**LO3.2.2** 可视化地呈现选定的AI系统如何工作，包括它们如何被训练和测试，以及使用的典型模型、算法和数据集。\<br\>\<br\>**LO3.2.3** 展示关于数据、算法和编码的可迁移知识，并将其应用于解决与其能力和角色范围相适应的问题。\<br\>\<br\>**LO3.2.4** 审辨式地应用与数据、训练、算法和AI模型相关的知识与技能，以评估植根于AI工具设计中的伦理。 | **在学校中熟练使用AI工具：** 基于对不同类别AI技术优势和局限性的深刻理解，熟练操作广泛使用的AI工具。\<br\>\<br\>**典型AI工具类别的可视化“知识”：** 绘制概念图或可视化工作流程，以解释选定的AI系统是如何被训练以及它们如何工作的。\<br\>\<br\>**引导学生学习数据、算法和编码：** 引导初学者水平的学生或同事教师获取与数据、算法和编码相关的知识与技能。\<br\>\<br\>**设计伦理中的知情揭示：** 应用关于AI如何被训练的理解，并展示调查可能植根于数据集、数据标注、算法和训练方法中的性别偏见和对残障人士或弱势群体的歧视的能力。揭示并报告任何基于证据的偏见或伦理风险发现。 |
| **AI教学法** |
| **4.2 AI与教学法融合：**\<br\>教师能够熟练地将AI融入以学生为中心的学习实践的设计和引导中，以促进参与、支持差异化学习并增强师生互动，旨在培养学生的共情以及审辨思维和解决问题的能力。 | **CG4.2.1** 基于AI赋能学习实践的典范视频，设计并组织学习策略；支持教师分析AI对学习过程、师生互动、学业学习成果以及社交与情感学习的影响；培养教师对学习设计、AI工具及其使用的适宜性以及对不同能力学生的包容性的理解；促进教师对他们设计或引导的AI辅助学习活动进行自我反思。\<br\>\<br\>**CG4.2.2** 通过鼓励教师讨论选定的研究报告或围绕AI对学生能动性、思维和学习过程的影响、与教师的互动、学业成果以及他们的社交情感学习等关键主题进行行动研究，来深化对AI影响的理解；引导教师理解AI辅助学习活动的益处和风险。\<br\>\<br\>**CG4.2.3** 支持整合部署关于AI的基础知识和技能以满足教学、学习和评估的需求；在适用情况下，引导教师应用教学原则来审阅学校采用的集成式AI辅助学习系统的主要功能。\<br\>\<br\>**CG4.2.4** 在AI的验证和教学使用背景下，支持从教学设计向学习设计的转变；组织教师进行实践操作，基于对AI在学习资源准备、思维和学习过程、人际互动、表现监测和评估中使用的综合考虑，来设计和引导AI辅助的学习活动；支持教师在“学习设计-学习引导-反思-再设计”的迭代循环中进行基于实践的反思和再设计。 | **LO4.2.1** 熟练地将伦理原则、以学生为中心的教学方法论和关于学习目标的跨学科视角融入其学习设计实践中；这可以涵盖从他们对AI工具的评估和融合，到他们的教学、学习和评估设计，再到他们对师生互动的规划和学习的引导。\<br\>\<br\>**LO4.2.2** 审辨式地评估各类AI或特定工具在辅助微课程或课程的共同设计、增强以学生为中心的教学、辅助形成性评估、监测学习过程、为个性化学生参与提供建议以及促进增强的人际互动方面是否展现优势；在可以验证AI优势的情况下，将AI工具和资源融入以学生为中心的教学实践中，以增强学生的高阶思维、理解、知识与技能应用、适当的社交互动和价值取向。\<br\>\<br\>**LO4.2.3** 审辨式地审视在形成性学习评估和高风险考试中使用特定AI应用或集成式AI辅助学习系统（如LMS）的适宜性；在具有明显优势时，熟练地融合合适的工具以促进AI辅助的形成性评估的设计和管理，以及由人负责的决策循环，以支持学生的学习成果、智力发展和心理发展。 | **AI工具和应用技能的图谱绘制：** 更新或扩展AI工具的概念图，以反映各类AI工具的关键特征，评估它们对以学生为中心的教学活动的教学可供性，并反思自身进步和进一步提升技能的需求。\<br\>\<br\>**洞察AI工具背后的教学假设：** 与同事或专家合作，审视通用AI系统的设计是否考虑了教学影响，以及这些教学影响对不同类别的AI意味着什么；理解并解释某一特定教育AI工具或系统所依据的关键教学假设。\<br\>\<br\>**为高阶思维和社交情感学习设计和引导学生使用AI：** 基于已验证的教育AI工具，设计以学生为中心的教与学活动，并引导学生使用AI以支持高阶思维、协作以及社交和情感学习。\<br\>\<br\>**由人负责的AI辅助评估：** 通过审视AI在提供反馈和对学生学习成果做决策时侵占由人负责的风险，来揭穿围绕使用AI自动化设计、管理和评分评估的迷思。考虑本地教育系统在评估结构方面的局限性，并分析在总结性评估和考试中使用AI的潜在益处和风险之间的可能权衡。在关于学习成果的决策中坚持确保由人负责，并防止使用AI对学习者的社会、伦理和心理发展做出判断和预测。 |
| **AI赋能专业发展** |
| **5.2 AI增强组织学习：**\<br\>教师能够自信地利用AI工具，有针对性地参与协作式专业学习社群，利用它们共享资源、参与同伴互助学习，并为动态适应做出贡献。 | **CG5.2.1** 激发持续的专业学习和协作动力，支持教师进行研究并讨论关于骨干教师如何在富含AI的环境中调整其角色和教学实践的案例研究，深化他们对教师根本上的人类角色与发展AI能力的义务之间平衡的理解。\<br\>\<br\>**CG5.2.2** 促进关于用于专业发展的AI工具的知识扩展，介绍本地可及的新兴工具，并推广那些包含对残障教师和/或与残障学生共事教师条款的工具。\<br\>\<br\>**CG5.2.3** 深化教师在使用数据分析支持专业学习方面的操作技能；引导教师转移和升级其在使用数据追踪和分析专业发展过程方面的知识和技能，包括在学科知识、教学法和实践表现方面，以促进数据驱动的自我诊断和学习路径的定制。\<br\>\<br\>**CG5.2.4** 提供评估与使用AI系统进行专业学习相关的更深层次伦理问题的手动实践；支持教师应用其关于“设计即伦理”的知识和技能，分析社交媒体平台、内容推荐平台和面向教师的AI工具中的AI算法在损害教师人权、数据隐私以及专业学习和协作方面的风险；推荐有效使用AI平台以寻找相关资源和实践社群以促进同伴学习的指导方针。 | **LO5.2.1** 审辨式地分析其在设计和引导学生使用AI的教学实践中的角色，深化他们对自身根本上的人类角色与持续发展AI能力的义务之间平衡的理解。\<br\>\<br\>**LO5.2.2** 应用关于数据的基础知识和技能，使用AI工具来追踪和分析自身的专业发展，包括在学科知识、教学知识和实践能力方面，以促进数据驱动的自我诊断和对其专业轨迹的自主规划。\<br\>\<br\>**LO5.2.3** 扩展关于使用AI，特别是新兴工具，以促进自身专业发展的知识和技能；推广使用支持残障教师或与残障学生共事教师的AI工具，包括使用可重新用于支持教师专业发展的本地相关开源工具。\<br\>\<br\>**LO5.2.4** 评估社交媒体平台和专业工具背后的AI算法在涉及教师人权、数据隐私和专业学习方面的伦理风险；制定并实施有效使用AI平台以寻找相关资源和实践社群以促进同伴学习的指导方针。 | **自主技能提升和同伴指导：** 紧跟新兴AI技术及其在本地情境中对教育的影响，自主地提升技能和再培训技能，并指导同事也这样做。\<br\>\<br\>**使用数据分析进行自我调节的专业发展：** 应用其关于数据、算法和AI模型的知识和技能，对教师自身的专业知识和技能进行分析；准确识别差距，并帮助他们调节自身的专业发展活动。\<br\>\<br\>**用于专业发展的生成式AI模拟：** 利用现有的生成式AI工具或定制新的工具，创建一个模拟特定专业发展场景的AI教练，以便教师可以练习并获得反馈——例子可以包括处理一个困难的班级、关于本地法规的培训，或模拟有困难的学生的情况。\<br\>\<br\>**由人控制地使用AI进行协作式专业发展：** 揭示AI操纵平台的伦理风险，并实施预防措施以避免负面影响。设计由人控制的活动，以利用AI平台或工具来界定资源范围或提供在线指导，以支持协作式专业发展。 |

好的，这是该章节内容的标准翻译，已为您整理为Markdown格式。

### **4.3 进阶水平3：创造 (Create)**

“创造”水平的课程目标是赋能那些拥有扎实AI知识和能力的教师，使其成为**专家型教师**和**变革的推动者**。他们应能够创新地将AI用于教育，并与社区合作，探索AI如何能够驱动教与学实践的理想转型。以下细则突出了“创造”水平的**探索性特征**，界定了主要能力、可衡量的学习目标和示例活动。

**表4. 进阶水平3（创造）的能力模块、目标与示例**

| **创造 (Create)** |
| :--- |
| **教师能力** | **课程目标 (CG)**\<br\>*(教师培训或支持项目应…)* | **学习目标 (LO)**\<br\>*(教师能够…)* | **情境化活动**\<br\>*(教师能够展现以下态度或行为上的改变)* |
| **以人为本的思维模式** |
| **1.3 社会责任：**\<br\>教师能够在一个对AI之于社会规范的影响有审辨式理解的指导下，积极参与并为构建包容性AI社会做出贡献，促进为增进人类福祉、包容和社会正义而设计和使用AI。 | **CG1.3.1** 培养对保护社交与情感福祉免受商业驱动的AI操纵重要性的审辨式理解；组织教师就AI公司如何通过强化个人成瘾和孤立、宣扬个人主义和自私以及对社会身份进行排名来产生利润进行辩论或基于研究的学习；引导教师形成动态和多方面的理解，即确保人人享有人权和促进社会正义是AI伦理的基石，并激励他们就制衡商业利益与人类社交情感福祉及地球上非人类物种健康的重要性提出并分享批判性见解。\<br\>\<br\>**CG1.3.2** 提供重新构想安全、包容和公正的AI社会的机会；组织工作坊、小组讨论和协作活动，供教师思考AI时代一个包容、公正和气候友好的社会秩序可能是什么样子，AI可能对这些社会规范构成何种威胁，以及有哪些可用的或应制定的契约或法规。\<br\>\<br\>**CG1.3.3** 通过组织实践工作坊来界定AI时代的公民身份，鼓励教师探索其法律和社会责任可能如何演变，并讨论在AI时代维护和加强公民需承担的核心社会权利和义务的方式，从而鼓励将作为AI社会公民的社会责任内化。 | **LO1.3.1** 审辨式地评估和反思AI对整个社会的影响，特别是它可能如何影响教育、工作、人际互动以及人与人之间和与环境的联系。\<br\>\<br\>**LO1.3.2** 在机构、地方和/或国家层面，积极为制定与教育中AI相关的政策做出贡献，包括如何利用AI的益处并减轻其社会和教育风险。\<br\>\<br\>**LO1.3.3** 在AI时代，个性化并实现社会和公民责任，并通过教育促进此类公民素质的发展。 | **教师在AI时代就人类与地球福祉发声：** 基于真实案例研究或研究发现的综合，撰写关于利润驱动的AI提供商如何威胁人类的社交与情感福祉及地球福祉的思想片段、文章或在线博客文章，并阐述其对教育的影响。\<br\>\<br\>**反思并促进以人为中心的社会关系和社会凝聚力：** 撰写博客或倡导对话，讨论AI时代理想的社会关系和社会凝聚力可以是什么样子，建立人际关系和社会秩序的技术和经济障碍，并列出为实现我们想要的社会而正在制定的全球和地方契约。\<br\>\<br\>**AI时代的公民权利、义务和责任：** 参与讨论、咨询或为起草界定AI时代公民权利、义务和责任的政策做出贡献。 |
| **AI伦理** |
| **2.3 共创伦理规则：**\<br\>教师能够通过审辨式倡导来捍卫AI伦理，领导处理AI设计和使用中伦理、社会文化和环境问题的讨论和行动，并为共创教育中AI实践的伦理规则做出贡献。 | **CG2.3.1** 通过组织教师对选定AI工具的社会影响进行基于研究的审阅，来促进对AI社会影响的探究；鼓励教师参与并评估这些工具如何影响地方经济、社会正义和气候变化，以及加剧对某些语言和文化社群或有特殊需求群体的歧视和排斥的风险；基于研究发现组织对话或辩论。\<br\>\<br\>**CG2.3.2** 通过邀请教师评估选定工具在可能边缘化残障人士、放大社会歧视以及威胁语言和文化多样性方面的风险，来加强对AI提供商发布的用户指南的审辨式审视；将用户指南与负面影响的可能性进行比较；收集反馈并起草关于如何修订用户指南的反馈意见。\<br\>\<br\>**CG2.3.3** 升级关于AI伦理的知识和技能，以指导伦理规则和标准的进一步迭代；引导教师搜索和审阅AI法规采纳背后的多利益相关方谈判（如欧洲《AI法案》背后的谈判）；从政策制定者、监管机构、律师、研究人员、AI公司以及使用AI工具的成人、儿童和机构的视角，模拟关于如何修订选定监管框架的多利益相关方辩论；起草一份共识或争议备忘录。 | **LO2.3.1** 从全球和地方的视角，审辨式地分析AI的社会影响，并深入了解新兴AI技术对社会公平、包容、语言和文化多样性、机构和个人安全保障、儿童智力和社会发展以及地球福祉的潜在影响。\<br\>\<br\>**LO2.3.2** 对照特定AI工具设计中根植的伦理风险及其使用可能引起的潜在社会争议，评估该工具用户指南的适宜性和充分性，并相应地提出修正或改进指南的建议。\<br\>\<br\>**LO2.3.3** 巩固关于AI伦理的法规必须由人类利益相关方设计并为其服务的观点；倡导并参与对话、制定或进一步迭代地方或机构的监管框架或指导方针，以促进AI设计、验证、采纳、部署和应用中的伦理。 | **关于AI社会影响的本地化全球视野：** 整体审视AI对个人人权与发展、经济活动、社会正义和地球福祉的社会影响；将全球视野转化为地方影响，以调查AI对社会的作用。\<br\>\<br\>**聚焦用户指南中的伦理差距：** 对照风险和社会影响的完整清单，审计选定AI工具提供商所做的声明及其用户指南中的条款。监测对用户，特别是儿童、残障学生和弱势群体的潜在威胁或伤害。承担报告这些问题并向提供商和监管机构（如数据保护当局）提出投诉的责任。\<br\>\<br\>**作为AI伦理倡导者的骨干教师：** 在发起关于AI伦理的意识宣传活动、解释伦理原则、分享相关法规知识、促进关于AI安全的对话以及与社区合作修订现有法规和/或制定新伦理标准方面发挥积极作用。\<br\>\<br\>**共创教育AI工具的伦理原型：** 发起一个假设的AI开发项目，并邀请跨学科合作，汇集教师、学生和技术专家，共同设计一个解决特定教育需求的合乎道德的AI工具。 |
| **AI基础与应用** |
| **3.3 用AI进行创造：**\<br\>教师能够熟练地定制或修改AI工具，应用增强的概念知识和操作技能来创建AI辅助的包容性学习环境，并应对教育背景下更广泛的挑战。 | **CG3.3.1** 培养在定制AI工具方面的适应性和创造力；支持教师整合关于数据、算法、编程和AI模型的技能，以定制或设计工具来应对教育中的挑战，重点关注不同能力人群的需求以及在本地情境中保护语言和文化多样性。\<br\>\<br\>**CG3.3.2** 通过支持教师深化对开源AI与商业AI工具相比的优势、局限性和风险的审辨式观点，来培养对开源AI的审辨看法；支持教师学习如何审阅、调适和/或迭代开源AI工具。\<br\>\<br\>**CG3.3.3** 通过基于项目的学习，模拟和实践在共创AI工具中的适应性和创造力。设计并引导基于项目的学习实践，以模拟教师学习如何调适可及且可负担的“现成”商业AI模型/工具、半成品工具和/或开源工具包，以组装或创造新的AI工具，基于以人为本和合乎道德的方法来解决真实世界的问题；增强教师在解决复杂真实问题时的适应性、韧性以及澄清模糊、克服障碍和承担风险的能力。\<br\>\<br\>**CG3.3.4** 支持教师将价值观、知识和技能嵌入到现有的教育AI工具库中；为教师提供实践机会，以审视工具的伦理和教学适宜性，并迭代更新学校的AI工具库。 | **LO3.3.1** 展示专家型教师水平的关于AI系统设计的知识和技能，以及分析选定AI系统在解决本地教育情境中真实世界问题局限性的综合能力。\<br\>\<br\>**LO3.3.2** 应用关于数据、算法、编程和AI模型的适当知识和技能，以定制和/或组装现有的AI工具或半成品AI模型，来创造AI工具或微调开源AI系统，以创建既与本地情境和特定用例相关又可负担的解决方案。\<br\>\<br\>**LO3.3.3** 修订或界定用于全面测试自创AI工具以及用于优化和进一步迭代该工具的标准。\<br\>\<br\>**LO3.3.4** 基于个人和机构需求，为一个新的或现有的用户创建或定制的AI工具库做出贡献，并提倡专注于仅利用最适合教育的工具。 | **驱动为包容性而设计的AI工具：** 与一个共同创造者社群合作，为现有AI工具添加功能或设计新功能以促进可及性，目标是为残障人士提供AI或数字学习平台。设计AI工具以支持检测广泛使用的AI平台中的包容性可及性。\<br\>\<br\>**促进共创支持气候友好行动的AI工具：** 共同创造AI工具或组织黑客松，以促进学生设计推广气候教育或气候友好行动的AI工具（例如，追踪选定AI平台或学校能源消耗所致碳排放的AI工具）。\<br\>\<br\>**协调教育AI工具库的建设和使用：** 支持创建一个选定的可信赖和自创的教育AI工具库，该库可通过学校网站空间或公开分享（例如，在GitHub上）。在适当时，承担校本AI协调员的角色，为其他教师提供培训，以支持他们使用该库。 |
| **AI教学法** |
| **4.3 AI赋能的教学创新：**\<br\>教师能够：审辨式地评估AI对教学、学习和评估的影响；规划和引导AI沉浸式学习场景，以支持学生的特定学科或跨学科学习、审辨思维和问题解决；并利用数据和反馈来持续探索以学生为中心的教学创新。 | **CG4.3.1** 激发关于AI用于学生发展的可能场景的想法；基于AI赋能的开放学习选项的典范视频，如共创实践和探究式及项目式学习，设计并组织场景分析；促进教师审阅其在能力、AI资源和评估方面的准备情况；赋能教师构思关于可由AI实现的创新性开放和创造性学习实践的可行想法。\<br\>\<br\>**CG4.3.2** 为教师深入理解教学原则与AI可能触发的教学变革之间的相互作用提供支架；促进教师审议基本问题，如教育中哪些核心价值观不应被使用AI所削弱（例如，保护学生的人权、包容性和社会关系），应坚持哪些基本教学原则来指导在教育中使用AI（例如，促进学生的智力发展、培养创造力、鼓励构建多元观点和创新思想，以及培养社交和情感技能），以及AI可能如何颠覆或变革教学方法论。\<br\>\<br\>**CG4.3.3** 支持即兴运用技能以创造新的AI工具或扩展现有工具；为教师提供机会，以提高他们对已验证工具（包括机构教育AI系统）的理解，并组装或共创AI工具，以支持和评估学生的探究式及项目式学习、创造力、创新等。\<br\>\<br\>**CG4.3.4** 培育从学习设计到场景设计的转变。组织实践操作，让教师可以共同设计课程实践或人机互动场景，以探索何时以及如何使用AI来支持“学习-评估-反馈-适应”的循环；分析学生、教师和AI系统之间新颖的三角互动的利弊，并设计策略以利用其优势和减轻其风险；为教师提供机会，以丰富他们在设计和构建AI辅助的开放学习选项方面的实践技能，并培养学生的高阶智力能力、创造力和好奇心。 | **LO4.3.1** 审辨式地审视AI的进步与教学方法论演变之间的动态互动；利用AI技术的真正益处来实现教育目标，并识别现有教学法在充分利用新兴AI教育潜力方面的可能局限性；设计并进行基于证据的开放学习选项测试，以利用AI在支持适合年龄的探究式学习、知识创造、协作式项目学习和敏捷创造力方面的潜力。\<br\>\<br\>**LO4.3.2** 组装AI工具或共创新的AI应用，以满足包容性可及性、语言和文化相关性、能力适切的个性化学习需求、社会支持、探究式或项目式学习的需求。\<br\>\<br\>**LO4.3.3** 熟练设计AI增强的学习场景，以促进学生的高阶探究、开放探索、项目式学习、审辨思维和共同创造，同时确保人际互动；构建并引导学生使用AI，使学生能够控制自己的学习路径，对AI工具做出选择，并在做出AI辅助决策时承担责任，确保为人际互动和反思留出嵌入的时间和空间。\<br\>\<br\>**LO4.3.4** 设计并适当整合AI的使用，以支持数据收集和使用，从而支持学习分析和教学策略的调整。\<br\>\<br\>**LO4.3.5** 熟练使用AI生成跨文本、音频和视频的内容，以支持国家或校本教材、课程资源或数字材料的共同创造，这些材料需由课程开发者验证。\<br\>\<br\>**LO4.3.6** 整合AI的使用，以服务于教师的行政任务、教与学任务，以及与家长和当地社区的互动。 | **在利用AI开辟新教学视野的同时，引导AI的教学使用：** 坚持以人为本的教学原则，以指导AI在教学活动中的设计和使用（保护人权、人的能动性、学生的自主性和独立思考、语言和文化多样性、多元观点和多元表达）。不断挑战现有教学法的局限，并探索现有教与学方法是否足以充分利用AI的教育潜力。紧跟AI所实现的新兴学习场景，并审视它们是现有教学方法的延伸还是代表了教学创新。\<br\>\<br\>**构建教师、学生和AI之间的三角互动：** 理解并持续审视AI，特别是生成式AI，在整个教与学过程中如何与教师和学生互动，以及生成式AI在多大程度上可以嵌入到思维过程和知识探索与建构过程中。驾驭“教师-AI-学生”的三角关系；设计并构建理想的“师生”、“师-AI”、“生-AI”和“师-AI-生”互动场景。\<br\>\<br\>**AI赋能有特殊需求的学生：** 推广辅助性AI或共创辅助性AI工具，并设计活动，为残障和有特殊需求的学生提供赋能机会，同时保护他们的人权和隐私。\<br\>\<br\>**课程资源开发的人机混合方法：** 持续参与使用AI以促进对现有文献的审阅和结合文本、音频和视频材料的包容性、可及性课程资源的制作；共创并实施一个由人负责的验证机制，用于AI辅助的课程资源制作。 |
| **AI赋能专业发展** |
| **5.3 AI支持专业发展：**\<br\>教师能够定制和修改AI工具以增强其专业发展，并持续测试和验证有效使用AI的策略，以满足其自身及其社群的专业发展需求。 | **CG5.3.1** 通过组织关于专家型教师如何能够为AI可能触发的教育转型提供信息和倡导的案例研究和/或讨论，来激励教师成为变革的推动者，通过模拟示例和有趣的练习培养变革推动者的特质。\<br\>\<br\>**CG5.3.2** 增强使用AI支持机构专业学习的技能；提供实践工作坊的机会，让教师共同创造AI工具来追踪某个机构或群体的专业发展，旨在促进数据驱动的监测、诊断和关于组织学习的建议。\<br\>\<br\>**CG5.3.3** 支持教师定制或组装AI工具，以为有残障或特殊需求的同事提供专业发展机会。\<br\>\<br\>**CG5.3.4** 培养作为AI创造性使用者以促进自我实现和转型的特质；召集实践工作坊，让教师可以为共创AI工具建立社群；鼓励教师与实践社群就如何利用AI来激发专业转型的问题进行互动。 | **LO5.3.1** 在共创和使用AI工具及方法以履行其在AI社会中的专业和社会责任方面，表现出承诺和坚持，旨在实现伦理规则的新迭代、定制化的AI解决方案和变革性的教学方法。\<br\>\<br\>**LO5.3.2** 融合AI工具和人类指导，以促进信息充分的自我反思和评估、目标设定以及知识和人类导师的动员，以支持个人和协作的转型。\<br\>\<br\>**LO5.3.3** 在可能的情况下，配置或创造AI解决方案来监测和审辨式地评估组织范围内的专业学习轨迹，并融合AI和其他方法来收集和综合建设性的反馈和可操作的建议。\<br\>\<br\>**LO5.3.4** 从作为一名教师的视角，理解AI在支持AI时代自我实现和个性化公民身份方面的作用；为教育社群共创AI工具以支持AI时代教师的自我实现和专业转型做出贡献。 | **教师的人机混合教练：** 构建或利用现有的生成式AI工具包，为教师的专业发展定制一个AI辅助的代理或教练，以支持自我评估和诊断等活动，以及模拟特定场景以练习技能并接收反馈（例如，满足有学习困难学生的需求或解决与使用AI相关的伦理困境）。也使用该代理或教练来帮助他们的同事。\<br\>\<br\>**AI赋能的培训项目设计：** 利用AI工具扩大对与特定教师群体需求相关的现有项目的审阅，扩展关于培训内容和培训方法的想法，并协助制作包容性、可及性的培训课程，这些课程需由人类总培训师或引导者验证。\<br\>\<br\>**共创AI工具、教学创新或伦理规则的社群：** 领导或参与致力于创新教学方法论的协作研究团队，和/或致力于为教育共创可信赖、可及和包容的AI工具或迭代更新AI使用伦理规则的社群。 |
