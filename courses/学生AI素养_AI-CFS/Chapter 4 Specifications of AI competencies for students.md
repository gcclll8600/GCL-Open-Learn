### **第4章：学生人工智能能力详解**

本《学生人工智能能力框架》（AI CFS）的以下详解，将阐明每个能力模块在**课程目标、适宜的教学方法和所需的学习环境**方面的具体内容，同时考虑了包容性以及AI准备情况的差异。

下述详解基于一个前提，即学生的AI能力是以下几方面**综合作用**的结果：国家AI课程、课外项目、通过包括互联网在内的各种媒介进行的非正式学习，以及与家庭和当地社区的互动。为指导AI课程的开发，本框架在考虑社会情境中非正式学习影响的同时，明确了正式AI课程的预期学习成果和行为表现。无论是作为一门特定学科，还是作为计算机科学或信息与通信技术（ICT）等相关学科内的模块，引入课程的AI相关学习都应在一个学期内，或最好是跨越多个学期，**分配充足的教学时间**。

所指定的课程目标概述了适用于初次接触AI相关学习的、不同年龄和能力水平学生的特定领域价值观、知识和技能。具体的学习目标应由国家或机构的课程部门，根据其学生和教师的AI准备情况、可用的教学时间以及地方学习环境来确定。这些详解包含了根据课程目标配置这些环境的建议，涉及**包容性、开源方案的潜力，以及与学术机构和私营部门共享AI资源**等方面。

最后，这些详解还针对特定AI领域在特定进阶水平上提出了教学方法。这些方法可能会启发教师和学生探索与具体情境和需求相关的敏捷教学模式。

#### **4.1 水平1：理解 (Level 1: Understand)**

此水平的总体目标是支持所有学生**理解AI是什么**，并对AI工具及其使用背后的价值观、伦理问题、概念、过程和技术方法**构建出符合其年龄的解读**。还应支持学生将他们的AI知识与现实生活经验联系起来，并将特定领域的AI知识与相关学习领域的知识联系起来。

表2（原文后续表格）中概述的课程目标有助于描绘一套确保学生正确有效使用AI所需的基础价值观、伦理原则、知识和理解——这种能力有时被称为**“AI素养”**。建议的教学方法旨在促进适合年龄和领域的教与学实践，这些实践有可能激发学生的兴趣，并基于具体的工具、个人经验和真实世界的使用场景来支持他们的学习轨迹。详解还推荐了基础的学习环境设置，其中包括使用**无设备（unplugged）和低技术方案**进行练习。

### **表2. 水平1：理解 (Understand) 的能力模块详解**

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **以人为本的思维模式** \<br\> **4.1.1 人类能动性** \<br\>\<br\> • 学生应能认识到AI是**由人主导的**，AI创造者的决定会影响AI系统对人权、人机交互以及他们自己生活和社会的影响。他们应理解在AI的设计、提供和使用过程中保护**人类能动性**的意义。学生将理解AI由人控制意味着什么，以及如果不由人控制可能会产生什么后果。 | • **CG4.1.1.1 培养对“AI由人主导”的理解：** 基于选定的AI工具，向学生解释AI是由人主导的；引导学生逐步、整体地理解人类能动性，这可能涵盖数据所有权和数据隐私、在数据收集和处理中保护人权、AI方法的可解释性、部署中的人类控制，以及在使用AI进行决策时的人类决定权等原则。引导学生理解AI不能取代人类的思维或智力发展。\<br\>\<br\> • **CG4.1.1.2 促进对“对AI进行充分人类控制”必要性的理解：** 让学生接触真实世界的情景，引导他们体验在控制AI方面人类监督缺失的后果（例如，薄弱的法规未能阻止有害AI工具的设计和生产；机构使用AI代替人类做出**高风险决策**；以及对AI输出的准确性缺乏人类验证）。帮助学生领会对AI进行人类控制的必要性。 | • **将AI生命周期中抽象的“人类能动性”概念可视化：** 要求学生绘制选定AI工具生命周期关键步骤中的人类能动性概念图，包括数据所有权、在收集和处理数据时尊重数据隐私、AI算法和模型的可解释性、对AI输出的人类控制评估，以及在AI辅助决策中的人类决定权。概念图还应反映在每个步骤中丧失人类能动性对个人和社会的潜在后果。\<br\>\<br\> • **模拟《人工智能法案》法庭辩论，以评估被禁AI系统背后的创造者意图：** 基于对欧盟《人工智能法案》中被禁止的AI系统定义的适龄解读，组织学生扮演**陪审团成员**，评估一些根据该法案将被禁止的AI系统案例，审议其创造者的意图和动机可能是什么。帮助学生理解这些系统如何对人类造成伤害，特别是通过削弱人类能动性。 | • **无设备（Unplugged）学习环境**，如纸质文章、印刷阅读材料和工作表。\<br\>\<br\> • 本地可用的AI工具，包括带有AI应用的**手机**。\<br\>\<br\> • 预先下载或录制的视频及其他与特定案例研究或两难情景相关的资源。\<br\>\<br\> • **搜索引擎**、在线视频和补充性的在线学习课程。 |


| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| (接上文) \<br\>...在法规、机构和个人层面建立系统，以保护人类的安全、道德和尊严。 | • **CG4.1.1.3 培养对人与机器能动性动态关系的批判性思维：** 让学生接触AI可以支持人类能动性和人类决策环的真实案例，支持学生理解人类如何能恰当地与AI互动以增强人类能力。引导学生就人类能动性与AI能动性之间的动态边界进行**冲突式辩论**，揭示在某些情况下可能需要一定程度的机器能动性（例如，在诊断罕见疾病时检测人类医生无法发现的医疗模式；人类起草报告时的自动拼写检查和纠错；开发课程材料时的自动字幕或自动化视频制作；自动语言翻译等）。培养一种批判性观点：即在使用AI做出**高风险决策**时必须坚持人类能动性，但在现实世界中，人与机器能动性的关系应根据具体需求和情境因素进行审视。 | (接上文) \<br\>...例如，一个AI系统可能会利用技术来削弱一个人的意识，或故意损害其做出知情决策的能力。\<br\>\<br\> • **基于场景理解由人控制的AI交互：** 选取在工作场所或日常生活中使用AI工具的例子或场景，标示出它们及其人类用户对目标任务单元的贡献。鼓励学生认识到在人类能力和智力可能存在局限的场景中AI可以做出的贡献，同时强调使用AI增强人类能力并确保人类控制的重要性。\<br\>\<br\> • **辩论人与机器能动性之间的动态边界：** 基于围绕人类对机器能动性依赖的现实两难案例，鼓励学生就人类和AI在AI支持的问题解决和决策过程中可能扮演的不断变化的角色进行辩论。引导学生将不同情境下人类能动性与机器能动性之间的抽象边界可视化。 | (同上) |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能伦理** \<br\> **4.1.2 具身伦理** \<br\>\<br\> • 学生应能对围绕AI的**伦理问题**以及AI对人权、社会正义、包容、公平和气候变化在其地方背景和个人生活中的潜在影响形成基本理解。他们将理解并内化以下关键伦理原则，并在其反思性实践和日常学习生活中使用AI工具时应用这些原则：\<br\>  - **不伤害**：评估AI的法规遵从性及其侵犯人权的潜力。\<br\>  - **相称性**：评估AI的收益与风险及成本；评估其情境适宜性。\<br\>  - **非歧视**：检测偏见，促进包容性。\<br\>  - **可持续性**：理解AI的环境和社会影响。\<br\>  - **人类决定权**：强调在使用AI时的人类能动性与问责。\<br\>  - **透明性**：倡导用户了解AI运作和决策的权利。 | • **CG4.1.2.1 阐述围绕AI的两难困境，并识别伦理冲突背后的主要原因：** 基于具体的AI工具，引导学生发现个人或企业创造者在AI设计和开发中需要做出的两难决策（例如，最大化数据收集规模 vs. 保护数据所有权；为训练AI模型记录用户私人数据 vs. 保护其隐私；促进机器控制以产生利润 vs. 保证人类能动性的首要地位；以及优先考虑AI安全 vs. 加速AI的迭代）。支持学生将对这些两难困境的看法与围绕AI的伦理冲突背后的原因联系起来。\<br\>\<br\> • **CG4.1.2.2 促进对AI伦理原则及其个人影响的基于场景的理解：** 为学生提供机会，讨论围绕六个核心AI伦理原则的适龄真实案例：（1）“不伤害”，（2）相称性，（3）非歧视，（4）可持续性，（5）人类决定权，以及（6）透明性与可解释性。引导学生建立一个关于AI伦理的知识框架，并在评估他们生活和学校中使用的AI工具时加以实践。\<br\>\<br\> • **CG4.1.2.3 指导对AI伦理原则的具身反思和内化：** 引导学生理解AI伦理原则对他们的人权、数据隐私、安全、人类能动性，以及对公平、包容、社会正义和环境可持续性的影响。引导学生形成对伦理原则的具身理解；并提供机会反思有助于应对伦理挑战的个人态度（例如，倡导AI工具的包容性界面，促进AI领域的包容性，以及报告在AI工具中发现的歧视性偏见）。 | • **关于AI争议场景的案例研究：** 呈现适合年龄的真实或模拟场景，引导学生发现围绕AI工具及其使用的争议。讨论此类伦理冲突背后的主要原因，并促进学生绘制**信息图（infographics）或概念图**来阐释核心的AI伦理原则。\<br\>\<br\> • **关于伦理困境个人影响的个人或小组反思：** 组织学生参与小组讨论，并就日常学习生活中使用AI可能产生的伦理困境发表意见（例如，大型语言模型是否应使用本地社区的数据进行训练；AI在多大程度上对环境有负面影响或能缓解气候变化；用户应放弃多少隐私来换取AI服务的益处）。引导学生通过论文、海报、绘画或**故事板（storyboards）等适合年龄的形式来表达他们的观点。\<br\>\<br\> • 寻找并验证“为公共利益服务的AI”案例： 组织个人或小组搜集支持公共利益（public good）的AI工具或使用方法的案例，包括促进残障人士的公平与包容、保护语言和文化多样性，以及增进社会正义和环境可持续性。引导学生收集证据并讨论真正服务于公共利益的案例；验证并分类这些案例。 | • 无设备（Unplugged）学习环境和材料，包括印刷的故事或案例研究、工作表和海报。\<br\>\<br\> • 本地可用的AI工具，包括通过手机应用**提供的工具。\<br\>\<br\> • 预先下载或录制的视频及其他与特定案例或呈现两难情景相关的资源。\<br\>\<br\> • **搜索引擎**、在线视频或与案例研究相关的资源。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能技术与应用** \<br\> **4.1.3 AI基础** \<br\>\<br\> • 学生应能建立关于AI的基础知识、理解和技能，特别是在**数据与算法**方面，并理解为逐步加深对数据和算法的理解所需的**跨学科基础知识**的重要性。学生还应能将关于AI的概念知识与他们在社会和日常生活中的活动联系起来，通过理解AI如何工作以及如何与人类互动，来**具体化以人为本的思维模式和伦理原则**。 | • **CG4.1.3.1 举例说明AI的定义和范围：** 基于AI工具的例子（如面部识别、社交媒体推荐、科学数据背后的模式分析、医疗诊断、自动驾驶汽车和预测贷款违约风险），促进学生理解什么是AI以及什么不是AI；引导学生寻找并分享主流AI技术类别下的范例工具，并以适合年龄的方式解释其主要功能和技术。\<br\>\<br\> • **CG4.1.3.2 建立关于AI如何基于数据和算法进行训练的概念知识：** 培养学生基于实例抽象出关于机器学习模型如何使用数据和算法进行训练的概念知识；帮助学生对三种AI算法类型，即**监督学习、无监督学习和强化学习**，形成适合年龄的理解。这应包括这三种AI算法背后的数据是如何获取和标注的。**破除“AI将自动编程算法，人类无需学习算法”的说法**。\<br\>\<br\> • **CG4.1.3.3 培养对AI的开放思维和AI的跨学科基础：** 使学生能够获得关于AI方法和研究主题的适当知识，例如**人工神经网络**的使用以及**强人工智能**和**弱人工智能**之间的区别。为对AI有浓厚兴趣和能力的学生提供关于数据和算法的扩展学习机会。引导学生理解AI知识与STEM、语言和社会研究等学科知识之间的相互作用，并邀请他们巩固相关的跨学科知识以及反思AI对相关学科的相互影响。\<br\>\<br\> • **CG4.1.3.4 在AI的设计和使用中具体化以人为本的考量：** 组织基于工具的AI反思活动，以具象化学生对AI对生活、工作和社会关系影响的理解。强调人类在AI生命周期关键步骤中的角色（例如，研究员、架构工程师、数据工程师、数据工作者、Beta测试员、伦理与安全监管员、人机交互专家和系统合规审计员）。引导学生深入熟悉与使用数据训练AI系统相关的主要伦理问题。 | • **基于实例理解AI的定义和范围：** 探究并试验AI工具的例子（例如，在医疗领域使用监督学习和图像分类进行癌症诊断，或在商业环境中使用自然语言处理和生成式AI进行自动会议纪要和文献综述撰写）。基于选定的例子，帮助学生理解什么是AI以及什么不是AI，以及日常生活中采用的主流AI技术类别和经济社会活动。引导学生探索AI生命周期的关键步骤；在适当时，为特定的AI系统绘制生命周期图并标注所使用的关键AI技术。\<br\>\<br\> • **从实例到抽象概念，再从概念到具体技术的螺旋式学习：** 使用选定的例子引导学生抽象出机器学习模型的训练过程，包括问题定义、数据收集、数据处理、训练、评估、部署以及基于测试和反馈的迭代。支持学生发展关于（并在可能的情况下，操作）AI技术使用的适龄知识和基本技能，涉及数据集、算法、AI架构、计算环境设置、功能和界面设计以及部署场景规划。\<br\>\<br\> • **创新AI工具和AI创新用法的案例分析：** 组织学生寻找潜在的创新AI工具和/或AI的创新用法；引导学生识别这些应用中使用的关键技术和主流AI类别。促进他们撰写一篇**议论文**或进行**口头答辩**，论述这些AI技术在多大程度上可以帮助人类在其个人实践、经济或商业模式或社会服务中进行创新，和/或特定AI技术可能对伦理原则和人类能动性构成的风险。\<br\>\<br\> • **巩固AI的多学科基础，特别侧重于数学：** 基于讲座和基于问题的探究，帮助学生掌握现代AI系统植根于数学，学习数据和算法需要扎实的数学基础和多学科知识体系。培养学生发展AI所需的基本数学和跨学科技能，包括代数、概率与统计、数据结构以及诸如**K-近邻算法、K-均值聚类、线性回归和CART/决策树**等算法的相关内容。培养学生在用于复杂数据表示和矩阵数学的**线性代数**，以及用于理解机器学习和神经网络的**反向传播**和**梯度下降**的**微积分**方面的高阶知识。支持学生巩固和扩展他们其他的多学科基础知识，尤其是在科学、技术和工程领域。 | • **无设备（Unplugged）学习环境**和资源，包括教科书、短文、工作表和印刷材料。\<br\>\<br\> • 介绍AI创新或工具的在线或下载的视频及其他媒体。\<br\>\<br\> • 本地可用的AI工具，包括安装在**智能手机**上的基本AI辅助应用。\<br\>\<br\> • 在线AI工具，例如图像和/或视频生成器、生成式AI模型以及社交媒体上的视频推荐。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能系统设计** \<br\> **4.1.4 问题界定** \<br\>\<br\> • 学生应能理解\*\*“AI问题界定”**作为AI创新起点的重性。他们应能从法律、伦理和逻辑角度审视在特定情况下是否应使用AI；学生能在一个AI模型被训练以解决问题前，界定该问题的**边界、目标和约束\*\*；学生还应能获得构思和构建一个AI系统所需的知识和**项目规划技能**，包括评估不同AI技术的适宜性、界定数据需求，以及设计测试和反馈指标。 | • **CG4.1.4.1 为“何时不应使用AI”的批判性思维能力搭建脚手架：** 借鉴实例，引导学生发展批判性分析技能，以审视为何应使用或不应使用AI来应对某些现实世界的挑战（例如，提高机构生产力、社区的可持续发展，或人类决策的精确度和效率），并参考其对人类和环境的影响。明确在何时以及何种条件下，不能和/或不应将AI应用于某些问题（例如，当**非AI解决方案**能以更低的伦理风险和环境影响提供相同性能时，或当使用AI会削弱人类意识或操纵人类行为时）。\<br\>\<br\> • **CG4.1.4.2 支持获取和强化“界定待由AI系统解决的问题”的技能：** 基于一个模拟项目，支持学习和实践识别并界定一个应该且可能通过构建新AI模型来解决的问题的技能（例如，为少数族裔语言训练一个AI模型以更好地服务其社区，或为自动追踪目标区域的迁徙构建一个模型）。学生可以通过**制定问题陈述**来磨练其分析技能，这有助于避免在定义不清的问题上浪费时间和精力。\<br\>\<br\> • **CG4.1.4.3 发展评估AI系统对数据、算法和计算资源需求的技能：** 为学生提供机会，通过评估对数据、算法、编程语言、软件、计算能力和硬件的需求来发展规划技能；研究一个AI项目在数据可用性（考虑到法规和伦理限制）以及所需数据处理与工程、计算能力和硬件的总成本方面的可行性。 | • **模拟项目提案的评审：** 组织学生模拟一个项目提案的评审和论证过程。例如，提案可以是关于构建或选择一个AI系统。就项目中是否应使用AI来解决问题进行辩论，考虑的因素包括是否有足够的训练数据、伦理影响、环境影响，以及非AI解决方案是否能以更少的风险达到类似的效果。引导学生为评审勾勒出一个**核对清单（checkbox）**。\<br\>\<br\> • **模拟新AI系统设计的问题界定和论证：** 促进学生研究他们日常生活或社区中的问题（例如，在学校或志愿者工作中），并识别一个可能通过AI解决的问题（例如，为学校花园自动浇水，或帮助听力不佳的祖父母检测警报声）。支持学生通过预想关键特征（包括AI算法和数据集）来界定和定义问题，并产出相应的问题陈述。\<br\>\<br\> • **数据预处理实验室：** 使用一个基础数据集和一个现有AI模型的架构，组织关于基于不同版本的数据集来训练模型的实验（例如，一个分类神秘图像的挑战）。支持学生应用各种数据预处理技术，例如调整编码（如**数据增强、处理异常值和分析数据集偏斜/不平衡**）。支持他们基于修改后的数据集训练模型，并观察数据预处理如何影响模型的性能。 | • **无设备（Unplugged）学习环境**，包括工作表、纸质案例研究，以及AI系统设计的原型或计划的打印件。\<br\>\<br\> • 连接互联网的**数字设备**。\<br\>\<br\> • 选定的在线AI系统。 |

#### **4.2 水平2：应用 (Level 2: Apply)**

“应用”水平的总体目标是帮助学生构建一个**坚实且可迁移的AI概念知识结构**和相关技能体系，并习惯于应用以人为本的思维模式和伦理原则来指导对AI工具的评估、学习和实践。表3（原文后续表格）中的课程目标旨在指导规划一套核心的价值取向、实践性伦理原则和方法论知识，可用于定制课程模块和明确所有学生的**最终能力（exit competencies）**。

建议的教学方法旨在促进对概念知识的**基于问题的探究**和对操作技能的**基于任务的领会**，同时整合策略以保持学生对进一步学习的好奇心。在“应用”水平提供理想的学习环境涉及配置硬件、软件和应用程序，以支持AI操作和共同创造的实践，并考虑**开源方案**。

### **表3. 水平2：应用 (Apply) 的能力模块详解**

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **以人为本的思维模式** \<br\> **4.2.1 人类问责** \<br\>\<br\> • 学生应能认识到**人类问责**是AI创造者和AI服务提供者的**法律义务**，并理解在设计和使用AI时他们应承担何种人类问责。他们还应培养一种意识，即当使用AI辅助影响人类的决策时，人类问责是一项法律和社会责任，并坚守在做出**高风险决策**时不应**将决定权让渡给AI**的原则。他们还应增强对那些声称AI可以篡夺人类思维和决策的**误导性说法**的判断力和心态韧性。 | • **CG4.2.1.1 建立“人类问责是AI创造者和服务提供者的一项法律义务”的观点：** 利用关于由人主导的AI生命周期的先备知识和真实世界的诉讼案例，引导学生理解人类AI创造者、服务提供者以及部署AI工具的机构，需对AI系统或服务可能导致的法律问题、违规和侵权行为负责。解释如何追究AI创造者、提供者和机构用户在安全事件、设计和训练AI中的伦理风险，以及滥用AI服务控制用户等方面的问责。引导学生理解他们在学习创造AI工具或设计AI系统时，自身应承担何种人类问责。\<br\>\<br\> • **CG4.2.1.2 形成“在使用AI对人类事务做决策时，人类问责是一项法律和社会责任”的理解：** 引导学生分析用于辅助决策的AI工具的能力。批判性质疑某些AI工具的真实能力，并**破除围绕AI所谓决策能力的炒作**。协助学生评估机构使用AI在复杂情况下对人类做决策的后果，例如，分析学生接受高等教育机会的资质，或决定求职者的可雇佣性。引导讨论为何在使用AI时，人类问责对于保障人权和人类尊严至关重要。促进学生理解为何在做出高风险决策时，我们不应使用AI取代人类，例如评估一个自然人的价值观、推断其情感或预测其资质。AI算法不应用于给学生评分（如COVID-19期间发生的情况）或决定大学录取。\<br\>\<br\> • **CG4.2.1.3 培养“人类问责需要个人能力来引导AI的有目的使用”的个人态度：** 引导学生质疑文献综述、写作和艺术创作的自动化如何可能削弱人类的思维过程和智力发展。引导学生讨论他们可以采取哪些具体行动，以保护自己和同伴免受使用AI产出或预测来篡夺人类思想、智力实践和持续能力提升的影响。 | • **为AI创造者和服务提供者撰写人类问责指南：** 促进学生扮演AI创造者和数据所有者的角色，并讨论他们在维护数据收集与处理的人类控制、训练AI模型、设计功能与界面、部署AI系统以及监控与反馈循环方面的关键法律和伦理问责。引导他们为自己关于AI系统设计、训练和迭代的学习撰写**自律准则**，要求AI创造者为保护数据所有者和AI用户的权利负责。\<br\>\<br\> • **调查AI辅助决策对人类的影响及AI法规中的补救途径：** 要求学生寻找由AI决定或极大影响人类决策的例子（例如，银行使用AI辅助评估系统来批准或拒绝学生贷款申请，或酒店使用分析系统根据客人的位置和预订时使用的设备来预测其社会经济背景）。促进学生揭示人类和AI在决策循环关键步骤中的角色，并检查决策中的人类问-责是否符合当地适用或国际法规（如欧盟《人工智能法案》）。\<br\>\<br\> • **有目的地使用AI的场景化实践：** 让学生参与一些活动，在其中有目的地使用AI工具来练习写作技巧，并培养他们的探究式学习、高阶思维和创造力。引导学生讨论在没有人类问责的情况下使用AI（例如，提交由AI生成的论文）如何可能削弱人类的智力发展。促使他们勾勒出具体行动，以保护自己和同伴免受使用AI产出或预测来篡夺思维过程的影响，并让他们洞察学生需要具备何种能力，才能引导AI的使用服务于人类能力的发展。 | • **无设备（Unplugged）和/或线下**学习环境和资源，包括纸质案例研究、角色扮演脚本、视频、工作表和翻转图表。\<br\>\<br\> • **在线AI工具**，例如学习管理系统、社交媒体平台和生成式AI平台。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能伦理** \<br\> **4.2.2 安全和负责任的使用** \<br\>\<br\> • 学生应能遵循伦理原则和当地适用法规，进行负责任的AI实践。他们应能意识到泄露数据隐私的风险，并采取措施确保其数据仅在他们**审慎和知情的同意**下被收集、使用、共享、存档和删除。他们还应能意识到典型的AI事件和某些AI系统的特定风险，并能在使用AI时保护自己和同伴的安全。 | • **CG4.2.2.1 培养负责任使用AI的自我意识和习惯性遵守伦理原则：** 借鉴具体的AI工具和真实世界的使用场景，阐述有关负责任使用AI的伦理原则或法规条款。支持学生迭代建立和更新一份伦理原则核对清单，以确保他们在与AI系统互动时自身的行为合法且负责。引导学生实践并习惯性地遵守这些原则，例如保护个人数据和隐私、尊重版权、明确标注AI生成内容出现的位置，以及避免在AI系统中有涉及**虚假信息、错误信息、仇恨言论**或可识别个人敏感细节的输入或互动。\<br\>\<br\> • **CG4.2.2.2 提供机会以强化负责任使用AI的自律性：** 为学生提供机会，使其对使用AI时的个人、法律和伦理责任有适合其年龄的理解；强调违反法规的后果；建立并强化自律行为，特别是在涉及敏感个人数据、受版权保护的材料、描绘可识别人物的图像、AI生成或数字合成的内容，以及虚假信息、错误信息和仇恨言论的传播方面。\<br\>\<br\> • **CG4.2.2.3 深化关于安全使用AI的实践知识和对当地适用法规的认识：** 促进学生对AI的一般安全风险、特定AI工具的潜在安全风险以及典型的AI事件进行分类。引导学生深化对数据保护和隐私人权的知识，以及AI创造者在征得同意的情况下收集数据的法律责任，并指导他们实践相关策略，以确保其个人数据仅在他们知情同意的情况下被收集、使用、共享、存档和删除。让学生接触包含典型AI事件的模拟场景，以便他们能实践安全使用AI的预防性和互动性策略，并熟悉能够保护其安全或减轻AI事件负面影响的法规。 | • **为自律、负责任地使用AI设计一个“伦理工具包”：** 设计包含潜在伦理冲突的模拟场景（例如，与AI系统聊天时分享私人数据或受保护内容；在学校作业中使用AI生成的内容；使用他人图像创作视频；或传播虚假信息、错误信息或仇恨言论）。组织起草一份\*\*“伦理工具包”**，供用户在使用AI时习惯性地核对，其中包含从当地适用法规中摘录的条款以及个人在合法和合乎伦理地使用AI工具方面的责任。引导学生在没有监督的情况下使用AI时，实践遵守这些原则。\<br\>\<br\> • 典型AI事件和风险管理的模拟： 让学生接触直接伤害人类的模拟AI事件或可能造成威胁的AI危害。使他们熟悉预防性和互动性策略，以确保其个人数据仅在他们知情同意的情况下被收集、使用、共享、存档和删除。提出安全使用AI的技巧，并提升他们对那些能够保护其隐私和福祉，和/或在AI事件发生时减轻负面影响的法规的认识。\<br\>\<br\> • 用户对AI创造者数据隐私政策的审查： 鼓励学生搜索并下载AI创造者数据隐私政策的例子。引导他们利用关于数据所有者权利和AI创造者法律责任的知识，来检查这些政策是否符合相关法规。当他们发现违规行为时，要求他们起草一份向监管机构的**投诉信\*\*，和/或一份给AI创造者以改进其政策和实践合规性的**建议书**。\<br\>\<br\> • **辩论AI生成内容和人机交互产出的所有权：** 组织一场辩论，以引发学生对使用AI创作内容的所有权的思考。审查关于承认AI生成内容和资源版权的法规的可用性和适用性，以及相关法规如何认定融合了不同程度AI生成内容的智力工作。 | • **无设备（Unplugged）学习环境**和资源，包括纸质工作表、海报和伦理原则核对清单。\<br\>\<br\> • 预先下载的**隐私政策和AI法规**，以及关于AI安全、数据隐私和同意形式的法律或伦理案例。\<br\>\<br\> • 本地可用的AI工具，包括**智能手机应用**。\<br\>\<br\> • 在线AI工具，特别是包含**推荐算法和内容生成器**的平台。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能系统设计** \<br\> **4.2.4 架构设计** \<br\>\<br\> • 学生应能培养基本的方法论知识和技术技能，为AI系统配置一个**可扩展、可维护和可重用的架构**，涵盖数据、算法、模型和应用接口等层面。学生应能发展必要的跨学科技能，以利用数据集、编程工具和计算资源来构建一个**AI系统原型**。这包括期望他们在配置、构建和优化过程中应用深化的以人为本的价值观和伦理原则。 | • **CG4.2.4.1 为AI架构的方法论知识和技术技能的获取搭建脚手架：** 促进学生获取并实践必要的工程思维和操作技能，以评估各种AI架构，旨在基于一个已定义的问题陈述选择一个合适的解决方案，同时考虑开源方案。提供**项目式学习**机会，以支持他们获取关于配置一个AI系统原型架构的方法论知识，该架构包含**反偏见的数据结构**、一个**节能型AI模型**以最小化负面环境影响、以人为本的性能与服务设计，以及用以测试和改进配置成熟度的指标。\<br\>\<br\> • **CG4.2.4.2 支持构建AI系统所需的高级技术技能和项目管理能力的准备：** 提供项目式学习机会，以促进学生获取并应用构建一个为简单特定任务设计的AI系统原型所需的跨学科技术技能（例如，一个模仿经验丰富教师回应的聊天机器人）。探索数据集的利用和规范化、虚拟计算资源的组装，以及AI模型的选择和增强（例如，**超参数优化**）。引导学生模拟机器学习模型的训练，包括计算资源的实际使用和调用数据以基于选定和预处理过的数据集来训练模型。设计和安排机会，让学生获得**项目管理技能**，包括在可用资源下平衡AI系统的范围、协调责任的划分与共享，以及批判性地评估和利用AI资源。 | • **模拟AI架构配置的框架和组件评估：** 基于问题陈述和可行性研究，促进学生评估各种AI架构框架（例如，TensorFlow, PyTorch, 或 Scikit-learn）。模拟基于选定框架对架构组件（例如，数据层、算法层、AI模型层和接口层）的解决方案评估和选择。配置一个原型架构，包含所需的数据集、算法工具、AI模型和计算资源，主要功能和界面的设计，以及部署计划。引导学生通过**流程图、图表或伪代码**等抽象方式来沟通配置方案。\<br\>\<br\> • **模拟利用资源构建AI系统：** 促进学生基于本地托管的计算设备或本地可访问的云平台（例如，Hadoop或Spark），以及训练机器学习模型所需的操作系统（例如，GNU）和软件来构建模拟的AI系统。引导学生在成本与计算能力需求之间，以及在AI模型的稳健性与其环境影响之间进行权衡，旨在优化效率并最小化计算资源的浪费。模拟架构的增强，包括**超参数的优化**和/或对现有AI模型进行**微调**以解决简单问题（例如，在预训练模型之上进行**迁移学习**，或应用新颖的神经网络或对基础模型进行非平凡的修改）。练习使用计算资源和调用数据，以基于选定和预处理过的数据集来训练机器学习模型。 | • 展示如何对AI模型进行伦理和技术评估的**视频和指标**。\<br\>\<br\> • 基于计算机的或本地可访问的在线AI系统示例。\<br\>\<br\> • 基于计算机的数据集样本或本地可访问的公共数据集。\<br\>\<br\> • 用于AI编程的基于计算机的应用程序，或本地可访问的**在线开源AI编程库**。\<br\>\<br\> • 本地托管的或开源的**云计算**资源，以及机构通过云平台共享的其他资源。 |

#### **4.3 水平3：创造 (Level 3: Create)**

“创造”水平的总体目标是激励并赋能学生发展**高级能力**，以便能基于可定制的数据集、编程工具或AI模型来配置AI解决方案或打造新的AI工具，同时考虑开源方案。学生还将得到支持，以增强他们对更广泛的**AI共同创造者**社区的**归属感**，并提升他们在思想上对作为AI社会公民所需承担的社会责任的参与度。表4（原文后续表格）中展示的课程目标旨在启发勾勒出一套**高阶能力**，这套能力由先进的AI方法论知识、AI系统设计的工程技能，以及在创造和测试AI系统时遵守个人和企业社会责任的**适应性**所组成。

建议的教学方法和途径旨在帮助解决**非结构化问题（ill-structured problems）**并培养**高阶思维**，包括通过项目式学习、基于问题的方法论知识探索以及多方面伦理评估等方式。建议的学习环境就如何配置数据集、AI编程工具和必要的计算设备提出了建议，以支持**复杂学习**，同时考虑了共享AI资源和**批判性地利用**开源方案。

### **表4. 水平3：创造 (Create) 的能力模块详解**

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **以人为本的思维模式** \<br\> **4.3.1 AI社会公民身份** \<br\>\<br\> • 学生应能对AI对人类社会的影响建立**批判性观点**，并扩展其以人为本的价值观，以促进为**包容性和可持续发展**而进行的AI设计与使用。他们应能巩固其作为AI社会公民的**公民价值观**和社会责任感。学生还应能强化其开放的态度和终身的好奇心，以学习和使用AI来支持在AI时代的**自我实现**。 | • **CG4.3.1.1 培养作为批判性AI公民的意识：** 使学生能够对AI作为人类社会活动的支撑性基础设施被广泛采用获得基于证据的见解。培养他们对人类社会正面临的挑战的意识和批判性观点，例如，优先加速AI创新而牺牲安全性和包容性，或优先考虑安全和包容性准入。发展学生批判**AI放大的针对女性、边缘化族裔群体和社会经济弱势人群的偏见**的技能，以及批判AI对社会关系、规范和结构影响的技能。帮助揭示AI对社会产生深远影响背后的原因，并评估应如何调整法律、伦理和社会规则以应对这些挑战。\<br\>\<br\> • **CG4.3.1.2 培养在AI社会中的个人与社会责任：** 鼓励学生分享他们对理想的AI社会面貌的看法，并从AI使用者和设计者的双重角度，描绘公民为建设一个包容、可持续和公正的AI社会所需承担的主要责任和义务。支持学生不断完善其作为AI社会公民的个人责任。激励学生在复杂的真实情境中审视在AI设计和使用中坚守伦理原则的挑战，以增强其以人为本思维模式的韧性。\<br\>\<br\> • **CG4.3.1.3 培养作为AI公民的自我实现感和对AI的终身学习态度：** 引导学生动态地审视AI在各行各业的采用所带来的影响，以及在AI社会中生活和工作可能需要的能力组合。反思在AI无处不在的社会中的个人目标，并评估AI在自我实现方面的作用。支持学生建立一种适应性强且持之以恒的态度，以终身学习AI来支持他们的自我实现和对社会可持续发展的个人贡献。 | • **关于包容公正的AI社会与AI对包容、公正和可持续性构成威胁之间冲突的案例研究：** 组织关于包容公正的AI社会与AI对以人为本价值观构成风险之间典型冲突的案例研究或项目式学习。组织讨论何为可持续、包容和公正的社会。要求学生分析AI已被广泛嵌入社会基础设施的案例，并质疑AI如何可能放大偏见、扩大经济和社会不平等、削弱人类能动性以及加剧气候变化。激励学生就如何监管现有AI技术以及如何引导下一代AI的设计以对建设包容公正的社会做出积极贡献，表明并捍卫自己的立场。\<br\>\<br\> • **关于作为AI社会公民的个人社会责任的探究：** 安排学生进行小组讨论，探讨AI社会中公民的权利，并共同勾勒出公民应承担的主要义务和责任，同时考虑全球和地方背景，以及包容、公平、社会正义、以人为本的目的以及对环境和生态系统的影响等多个维度。这包括确保人类在AI生命周期的所有关键步骤中拥有控制权和问责权。允许学生进行并分享他们对在AI社会中个人社会责任的自我反思。\<br\>\<br\> • **关于AI社会中自我实现及其对终身学习影响的案例研究：** 组织关于在工作、生活和社会实践中采用AI的案例研究，并激励他们审视AI的采用对其个人目标、职业发展和自我实现的影响。引导学生建立一种适应性强且充满好奇的态度，以终身学习和使用AI来支持他们的自我实现和对社会可持续发展的个人贡献。 | • **无设备（Unplugged）学习环境**和资源，包括工作表、翻转图表、关于AI社会中就业和职业发展的报告或视频，以及关于AI社会意涵和环境影响的纸质分析性案例研究。\<br\>\<br\> • 用于体验和分析性测试的在线AI系统或本地可用的AI工具，包括提供**个人助理、聊天机器人和智能辅导系统**的智能手机应用。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能伦理** \<br\> **4.3.2 伦理设计** \<br\>\<br\> • 学生应能采纳\*\*“伦理设计” (ethics-by-design)\*\* 的方法，应用于AI工具的设计、评估和使用，以及AI法规的审查和调整。学生应意识到对AI设计意图的评估和确认应从**概念化阶段**开始，并贯穿AI生命周期的所有步骤。学生应能应用参数来评估一个AI工具是否符合伦理法规，并使用一个**多方利益相关者伦理矩阵**来审查AI法规并为调整提供信息。 | • **CG4.3.2.1 建立对“伦理设计”的意识和理解：** 提供基于冲突的学习机会，以便学生能在AI设计和创造的整个生命周期中应用一套完整的伦理原则。引导学生在AI工具处于概念化阶段、数据收集与工程中的反偏见措施、机器学习训练中的无歧视方法、生成AI输出的以人为本的\*\*“护栏” (guardrails)**，以及AI工具的包容性测试和审计等环节，评估其伦理适宜性。\<br\>\<br\> • CG4.3.2.2 培养对现有AI系统和算法背后伦理设计原则的批判性态度： 为学生提供机会，让他们采取整体方法来应用原则和法规，以评估特定AI系统或工具的“伦理设计”。通过要求他们向AI系统创造者提出建议，以纠正任何已发现的违反伦理原则或法规的行为，并减轻其AI工具已造成的任何伤害，来发展他们的批判性思维能力。\<br\>\<br\> • CG4.3.2.3 培养在AI法规中坚持“伦理设计”的社会责任： 借鉴选定的AI法规，引导学生评估它们与伦理设计方法的一致性程度，以及相应措施在监控和规范算法及AI系统中嵌入的典型伦理风险方面的充分性。通过引导他们为现有的地方性法规提出修改建议，或为在其社区内制定治理伦理设计的法规起草提案，来增强学生的社会责任意识和履行能力。 | • 模拟AI开发团队中“首席伦理官”的尽职调查： 设计项目式学习实践，要求学生模拟一个AI公司**首席伦理官 (chief ethics officer)\*\* 的角色，包括为审计AI系统设计的关键步骤起草一份伦理标准核对清单，并定义在监督一个团队或公司正在设计的AI系统的安全性和伦理性时需遵循的关键**尽职调查 (due diligence)** 程序。\<br\>\<br\> • **模拟使用“伦理标签”来审计选定的AI工具或算法：** 组织学生对选定的AI工具或系统中的“伦理设计”进行模拟审计。就此提供讲座，并支持学生研究AI系统的\*\*“伦理标签” (ethics label)**（AI系统的伦理标签类似于食品的营养标签）。引导学生构建或调整一个伦理标签，以审计选定AI系统和服务设计者的意图，包括收集其公开声明之外的信息（例如，一个购物推荐平台的创造者声称其意图是帮助顾客找到最合适的产品，而其隐藏目的可能是让用户依赖或沉迷于使用该平台）。就审计的发现撰写报告。\<br\>\<br\> • 模拟使用伦理矩阵来审查AI法规并提出调整建议： 邀请学生研究一个用于让相关利益相关者参与AI法规制定的伦理矩阵。支持他们构建一个适应性的**伦理矩阵\*\*，其列为核心伦理原则，行为相关利益相关者（例如，AI创造者、监管者、机构部署者和个人用户）。学生可以应用他们的矩阵来分析选定法规的相关条款，并起草报告或评论，包括对法规进行进一步调整或迭代的建议。在地方性法规缺失的情况下，撰写一份关于创建新AI法规的提案，并为相关利益相关者勾勒出条款大纲。 | • **无设备（Unplugged）学习环境**和资源，包括工作表、翻转图表和纸质的尽职调查核对与报告、伦理标签与矩阵、AI创造者的隐私政策以及AI法规的范例。\<br\>\<br\> • 本地可用的AI工具，包括**智能手机应用**。\<br\>\<br\> • 用于伦理分析的在线AI系统。\<br\>\<br\> • 分享AI法规和**诉讼或法庭案例**的网站。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能技术与应用** \<br\> **4.3.3 创造AI工具** \<br\>\<br\> • 学生应能深化和应用关于数据与算法的知识和技能，以**定制现有的AI工具包**来创造基于任务的AI工具。学生应能将他们以人为本的思维模式和伦理考量融入对现有AI资源的评估和对自创AI工具的测试中。他们还应能培养参与AI创造所需的**社交和情感技能**，包括适应性、复杂沟通和团队合作技能。 | • **CG4.3.3.1 激励并赋能开发基于任务的AI工具的高级技能：** 提供基于任务的学习机会，以便学生能将其价值观、知识和技能迁移到基于现有AI模型或工具包来打造一个AI工具上。支持他们掌握高级技能，包括批判性地分析现有AI工具与特定任务的相关性、评估其数据收集和处理需求、决定是采用**低代码方法**还是需要AI算法和编程语言，以及进行操作上的定制和/或编程。\<br\>\<br\> • **CG4.3.3.2 增强学生在应用AI知识和技能以定制AI工具包和编码方面的创造力：** 围绕定制AI工具以解决真实任务来设计任务。引导学生获得利用AI开发平台或工具包、增强数据集和修改编程代码（包括基于开源选项的代码）的技能；激励并支持学生探索和测试关于AI工具设计的创意，以解决各种变体问题。\<br\>\<br\> • **CG4.3.3.3 装备学生测试和优化其自创AI工具的技能：** 支持学生定制评估方法和工具，以测试他们自创AI工具的稳健性和易用性，学习如何组织同行评估和分享反馈，并作为共同创造者建立协作技能。 | • **为打造AI工具而进行的基于任务的数据集和编程代码增强：** 组织学生通过一个真实任务来修改数据集或创建一个新数据集，例如监控当地学校或家庭的能源消耗、为特定地点或路线预测天气，或追踪一种流行病。教导并促进学生利用自动数据收集工具（例如，用于从网页抓取信息的**BeautifulSoup**）；应用AI编程技能来清洗、编码和预处理数据；并使用这些数据来定制AI模型或打造AI工具。\<br\>\<br\> • **AI应用性能测试实验室：** 引导学生寻找并调整一个免费和/或开源的、用于测试AI应用的**性能指标**（例如，**准确率、精确率、F1分数、混淆矩阵和ROC曲线**）。让学生体验使用调整后的工具来测试所打造的AI应用的性能和技术稳健性，并模拟用户对伦理合规性的反馈。使用自动化工具生成可视化报告，并总结关于优化该AI应用的建议。\<br\>\<br\> • **通过定制数据集和编程代码创造AI工具与基于低代码开发平台构建AI应用的比较：** 组织学生搜索关于通过定制AI工具包的开源数据集和编程代码来创造AI工具所需的步骤和技能的信息。引导他们研究基于**低代码开发平台**构建AI应用的技能。组织讨论这两种方法在人类能动性和人类决定权、对本地社区数据的包容性和对本地文化多样性的反映，以及最终工具的可扩展性和可重用性方面的差异。讨论如何根据具体需求和情况在这两种方法之间做出选择。 | • 本地可访问的免费和/或**开源的在线数据集、AI工具和编程库**。\<br\>\<br\> • 本地可访问的免费和/或开源的**数据分析工具**。\<br\>\<br\> • 本地可访问的**基于云的计算资源**、本地托管的计算资源（例如，学校服务器），或由可信机构或行业机构共享的计算资源。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能系统设计** \<br\> **4.3.4 迭代与反馈** \<br\>\<br\> • 学生应能增强和应用其跨学科知识和实践方法，以评估一个AI模型的**人本主义适宜性**和**方法论稳健性**，及其对个人用户、社会和环境的影响。他们应能获得适合其年龄的技术技能，以根据测试和反馈的结果来**改进数据集质量、重新配置算法和增强架构**。他们应能应用以人为本的思维模式和伦理原则，来模拟关于何时应**关停**一个AI系统以及如何减轻其负面影响的决策。他们还应能在更广泛的AI社区中培养其作为**共同创造者**的身份认同。 | • **CG4.3.4.1 发展批判AI系统的技能：** 提供项目式学习机会，让学生实践批判性地测试AI系统的技术稳健性和批判其伦理适宜性的技能，具体通过审计模型是增强还是削弱了人类的能力、能动性和意识；检查其可解释性和对数据隐私的保护程度；衡量AI系统的性能；以及研究用户反馈以评估其更广泛的社会和环境影响。\<br\>\<br\> • **CG4.3.4.2 支持在优化、重新配置或关停AI系统方面的技术技能和社会责任建设：** 提供模拟活动，让学生理解企业社会责任，并获得跨学科技能，以根据测试结果和用户反馈对AI系统的迭代做出决策。活动应涉及发展学生应对三种可能情景的技术技能：（1）**优化**：优化数据集、算法、模型、设计功能和/或界面；（2）**重新配置**：重新审视问题界定并重新配置AI系统；以及（3）**关停**：当证明AI系统侵犯人权或伤害弱势群体时，学生应学习做出关停AI模型的决定，并迅速采取**补救策略**。\<br\>\<br\> • **CG4.3.4.3 培养学生作为AI时代共同创造者的自我认同：** 引导学生培养作为AI工具共同创造者和下一代AI技术设计“驱动者”的责任感。发展他们对更广泛AI社区的归属感，并鼓励他们借鉴设计和构建AI系统的真实经验，批判性地分析AI系统对社会关系和个人行为的长期影响。讨论应如何调整或创建法规或政策，以加强对AI的治理。 | • **模拟AI系统的性能测试：** 组织学生使用调整后的指标来衡量一个AI模型是增强还是削弱了人类的能力、能动性和意识，并评估其方法的可解释性程度。调整机器学习的性能指标和相关的可视化工具，包括开源选项（例如，机器学习中的F1分数、混淆矩阵和ROC曲线），以衡量AI系统的性能。设计并应用研究方法（例如，收集适合年龄的定性和定量市场数据），包括来自（模拟）最终用户的反馈，以研究采用该AI模型的社会意涵和环境影响。综合研究结果并以可视化格式报告。\<br\>\<br\> • **模拟AI工程师关于AI模型迭代的企业决策：** 组织学生扮演AI工程师的角色，整合并解读来自反馈的结果，同时考虑AI系统设计和企业社会责任。从关于AI模型迭代的多个选项中做出适当的决策：（1）**优化**，当问题界定得到验证，但数据集、算法、AI模型或界面可能需要优化时；（2）**重新配置**，当通过测试和/或用户反馈在问题界定和/或架构配置中发现根本性缺陷时；或（3）**关停**，当证明一个AI模型侵犯人权或伤害弱势群体时。支持学生获得优化和重新配置的技术技能，并学习就关停AI模型进行谈判和决策，以及了解可能的补救策略。\<br\>\<br\> • **与AI创造者社区的互动：** 促进有兴趣的学生加入本地或在线的AI共同创造者社区。鼓励他们参与在线讨论或AI工具的协作开发，并分享开源的数据集、算法示例或AI工具包。 | • 本地可访问的在线免费和/或开源AI工具，包括**数据分析工具和编程库**。\<br\>\<br\> • 本地托管的或本地可访问的**云计算资源**。\<br\>\<br\> • 已下载和调整过的用于对AI模型进行**伦理审计和性能测试**的工具。\<br\>\<br\> • 可获取的关于AI的适用**法规或治理框架**。\<br\>\<br\> • 本地可访问的**在线协作平台**，以支持资源共享、同伴学习以及AI工具的协作设计与创造（例如，**GitHub、arXiv或论坛小组**）。 |
