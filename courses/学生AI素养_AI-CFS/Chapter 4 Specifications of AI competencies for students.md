### **第4章：学生人工智能能力详解**

本《学生人工智能能力框架》（AI CFS）的以下详解，将阐明每个能力模块在**课程目标、适宜的教学方法和所需的学习环境**方面的具体内容，同时考虑了包容性以及AI准备情况的差异。

下述详解基于一个前提，即学生的AI能力是以下几方面**综合作用**的结果：国家AI课程、课外项目、通过包括互联网在内的各种媒介进行的非正式学习，以及与家庭和当地社区的互动。为指导AI课程的开发，本框架在考虑社会情境中非正式学习影响的同时，明确了正式AI课程的预期学习成果和行为表现。无论是作为一门特定学科，还是作为计算机科学或信息与通信技术（ICT）等相关学科内的模块，引入课程的AI相关学习都应在一个学期内，或最好是跨越多个学期，**分配充足的教学时间**。

所指定的课程目标概述了适用于初次接触AI相关学习的、不同年龄和能力水平学生的特定领域价值观、知识和技能。具体的学习目标应由国家或机构的课程部门，根据其学生和教师的AI准备情况、可用的教学时间以及地方学习环境来确定。这些详解包含了根据课程目标配置这些环境的建议，涉及**包容性、开源方案的潜力，以及与学术机构和私营部门共享AI资源**等方面。

最后，这些详解还针对特定AI领域在特定进阶水平上提出了教学方法。这些方法可能会启发教师和学生探索与具体情境和需求相关的敏捷教学模式。

#### **4.1 水平1：理解 (Level 1: Understand)**

此水平的总体目标是支持所有学生**理解AI是什么**，并对AI工具及其使用背后的价值观、伦理问题、概念、过程和技术方法**构建出符合其年龄的解读**。还应支持学生将他们的AI知识与现实生活经验联系起来，并将特定领域的AI知识与相关学习领域的知识联系起来。

表2（原文后续表格）中概述的课程目标有助于描绘一套确保学生正确有效使用AI所需的基础价值观、伦理原则、知识和理解——这种能力有时被称为**“AI素养”**。建议的教学方法旨在促进适合年龄和领域的教与学实践，这些实践有可能激发学生的兴趣，并基于具体的工具、个人经验和真实世界的使用场景来支持他们的学习轨迹。详解还推荐了基础的学习环境设置，其中包括使用**无设备（unplugged）和低技术方案**进行练习。

### **表2. 水平1：理解 (Understand) 的能力模块详解**

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **以人为本的思维模式** \<br\> **4.1.1 人类能动性** \<br\>\<br\> • 学生应能认识到AI是**由人主导的**，AI创造者的决定会影响AI系统对人权、人机交互以及他们自己生活和社会的影响。他们应理解在AI的设计、提供和使用过程中保护**人类能动性**的意义。学生将理解AI由人控制意味着什么，以及如果不由人控制可能会产生什么后果。 | • **CG4.1.1.1 培养对“AI由人主导”的理解：** 基于选定的AI工具，向学生解释AI是由人主导的；引导学生逐步、整体地理解人类能动性，这可能涵盖数据所有权和数据隐私、在数据收集和处理中保护人权、AI方法的可解释性、部署中的人类控制，以及在使用AI进行决策时的人类决定权等原则。引导学生理解AI不能取代人类的思维或智力发展。\<br\>\<br\> • **CG4.1.1.2 促进对“对AI进行充分人类控制”必要性的理解：** 让学生接触真实世界的情景，引导他们体验在控制AI方面人类监督缺失的后果（例如，薄弱的法规未能阻止有害AI工具的设计和生产；机构使用AI代替人类做出**高风险决策**；以及对AI输出的准确性缺乏人类验证）。帮助学生领会对AI进行人类控制的必要性。 | • **将AI生命周期中抽象的“人类能动性”概念可视化：** 要求学生绘制选定AI工具生命周期关键步骤中的人类能动性概念图，包括数据所有权、在收集和处理数据时尊重数据隐私、AI算法和模型的可解释性、对AI输出的人类控制评估，以及在AI辅助决策中的人类决定权。概念图还应反映在每个步骤中丧失人类能动性对个人和社会的潜在后果。\<br\>\<br\> • **模拟《人工智能法案》法庭辩论，以评估被禁AI系统背后的创造者意图：** 基于对欧盟《人工智能法案》中被禁止的AI系统定义的适龄解读，组织学生扮演**陪审团成员**，评估一些根据该法案将被禁止的AI系统案例，审议其创造者的意图和动机可能是什么。帮助学生理解这些系统如何对人类造成伤害，特别是通过削弱人类能动性。 | • **无设备（Unplugged）学习环境**，如纸质文章、印刷阅读材料和工作表。\<br\>\<br\> • 本地可用的AI工具，包括带有AI应用的**手机**。\<br\>\<br\> • 预先下载或录制的视频及其他与特定案例研究或两难情景相关的资源。\<br\>\<br\> • **搜索引擎**、在线视频和补充性的在线学习课程。 |


| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| (接上文) \<br\>...在法规、机构和个人层面建立系统，以保护人类的安全、道德和尊严。 | • **CG4.1.1.3 培养对人与机器能动性动态关系的批判性思维：** 让学生接触AI可以支持人类能动性和人类决策环的真实案例，支持学生理解人类如何能恰当地与AI互动以增强人类能力。引导学生就人类能动性与AI能动性之间的动态边界进行**冲突式辩论**，揭示在某些情况下可能需要一定程度的机器能动性（例如，在诊断罕见疾病时检测人类医生无法发现的医疗模式；人类起草报告时的自动拼写检查和纠错；开发课程材料时的自动字幕或自动化视频制作；自动语言翻译等）。培养一种批判性观点：即在使用AI做出**高风险决策**时必须坚持人类能动性，但在现实世界中，人与机器能动性的关系应根据具体需求和情境因素进行审视。 | (接上文) \<br\>...例如，一个AI系统可能会利用技术来削弱一个人的意识，或故意损害其做出知情决策的能力。\<br\>\<br\> • **基于场景理解由人控制的AI交互：** 选取在工作场所或日常生活中使用AI工具的例子或场景，标示出它们及其人类用户对目标任务单元的贡献。鼓励学生认识到在人类能力和智力可能存在局限的场景中AI可以做出的贡献，同时强调使用AI增强人类能力并确保人类控制的重要性。\<br\>\<br\> • **辩论人与机器能动性之间的动态边界：** 基于围绕人类对机器能动性依赖的现实两难案例，鼓励学生就人类和AI在AI支持的问题解决和决策过程中可能扮演的不断变化的角色进行辩论。引导学生将不同情境下人类能动性与机器能动性之间的抽象边界可视化。 | (同上) |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能伦理** \<br\> **4.1.2 具身伦理** \<br\>\<br\> • 学生应能对围绕AI的**伦理问题**以及AI对人权、社会正义、包容、公平和气候变化在其地方背景和个人生活中的潜在影响形成基本理解。他们将理解并内化以下关键伦理原则，并在其反思性实践和日常学习生活中使用AI工具时应用这些原则：\<br\>  - **不伤害**：评估AI的法规遵从性及其侵犯人权的潜力。\<br\>  - **相称性**：评估AI的收益与风险及成本；评估其情境适宜性。\<br\>  - **非歧视**：检测偏见，促进包容性。\<br\>  - **可持续性**：理解AI的环境和社会影响。\<br\>  - **人类决定权**：强调在使用AI时的人类能动性与问责。\<br\>  - **透明性**：倡导用户了解AI运作和决策的权利。 | • **CG4.1.2.1 阐述围绕AI的两难困境，并识别伦理冲突背后的主要原因：** 基于具体的AI工具，引导学生发现个人或企业创造者在AI设计和开发中需要做出的两难决策（例如，最大化数据收集规模 vs. 保护数据所有权；为训练AI模型记录用户私人数据 vs. 保护其隐私；促进机器控制以产生利润 vs. 保证人类能动性的首要地位；以及优先考虑AI安全 vs. 加速AI的迭代）。支持学生将对这些两难困境的看法与围绕AI的伦理冲突背后的原因联系起来。\<br\>\<br\> • **CG4.1.2.2 促进对AI伦理原则及其个人影响的基于场景的理解：** 为学生提供机会，讨论围绕六个核心AI伦理原则的适龄真实案例：（1）“不伤害”，（2）相称性，（3）非歧视，（4）可持续性，（5）人类决定权，以及（6）透明性与可解释性。引导学生建立一个关于AI伦理的知识框架，并在评估他们生活和学校中使用的AI工具时加以实践。\<br\>\<br\> • **CG4.1.2.3 指导对AI伦理原则的具身反思和内化：** 引导学生理解AI伦理原则对他们的人权、数据隐私、安全、人类能动性，以及对公平、包容、社会正义和环境可持续性的影响。引导学生形成对伦理原则的具身理解；并提供机会反思有助于应对伦理挑战的个人态度（例如，倡导AI工具的包容性界面，促进AI领域的包容性，以及报告在AI工具中发现的歧视性偏见）。 | • **关于AI争议场景的案例研究：** 呈现适合年龄的真实或模拟场景，引导学生发现围绕AI工具及其使用的争议。讨论此类伦理冲突背后的主要原因，并促进学生绘制**信息图（infographics）或概念图**来阐释核心的AI伦理原则。\<br\>\<br\> • **关于伦理困境个人影响的个人或小组反思：** 组织学生参与小组讨论，并就日常学习生活中使用AI可能产生的伦理困境发表意见（例如，大型语言模型是否应使用本地社区的数据进行训练；AI在多大程度上对环境有负面影响或能缓解气候变化；用户应放弃多少隐私来换取AI服务的益处）。引导学生通过论文、海报、绘画或**故事板（storyboards）等适合年龄的形式来表达他们的观点。\<br\>\<br\> • 寻找并验证“为公共利益服务的AI”案例： 组织个人或小组搜集支持公共利益（public good）的AI工具或使用方法的案例，包括促进残障人士的公平与包容、保护语言和文化多样性，以及增进社会正义和环境可持续性。引导学生收集证据并讨论真正服务于公共利益的案例；验证并分类这些案例。 | • 无设备（Unplugged）学习环境和材料，包括印刷的故事或案例研究、工作表和海报。\<br\>\<br\> • 本地可用的AI工具，包括通过手机应用**提供的工具。\<br\>\<br\> • 预先下载或录制的视频及其他与特定案例或呈现两难情景相关的资源。\<br\>\<br\> • **搜索引擎**、在线视频或与案例研究相关的资源。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能技术与应用** \<br\> **4.1.3 AI基础** \<br\>\<br\> • 学生应能建立关于AI的基础知识、理解和技能，特别是在**数据与算法**方面，并理解为逐步加深对数据和算法的理解所需的**跨学科基础知识**的重要性。学生还应能将关于AI的概念知识与他们在社会和日常生活中的活动联系起来，通过理解AI如何工作以及如何与人类互动，来**具体化以人为本的思维模式和伦理原则**。 | • **CG4.1.3.1 举例说明AI的定义和范围：** 基于AI工具的例子（如面部识别、社交媒体推荐、科学数据背后的模式分析、医疗诊断、自动驾驶汽车和预测贷款违约风险），促进学生理解什么是AI以及什么不是AI；引导学生寻找并分享主流AI技术类别下的范例工具，并以适合年龄的方式解释其主要功能和技术。\<br\>\<br\> • **CG4.1.3.2 建立关于AI如何基于数据和算法进行训练的概念知识：** 培养学生基于实例抽象出关于机器学习模型如何使用数据和算法进行训练的概念知识；帮助学生对三种AI算法类型，即**监督学习、无监督学习和强化学习**，形成适合年龄的理解。这应包括这三种AI算法背后的数据是如何获取和标注的。**破除“AI将自动编程算法，人类无需学习算法”的说法**。\<br\>\<br\> • **CG4.1.3.3 培养对AI的开放思维和AI的跨学科基础：** 使学生能够获得关于AI方法和研究主题的适当知识，例如**人工神经网络**的使用以及**强人工智能**和**弱人工智能**之间的区别。为对AI有浓厚兴趣和能力的学生提供关于数据和算法的扩展学习机会。引导学生理解AI知识与STEM、语言和社会研究等学科知识之间的相互作用，并邀请他们巩固相关的跨学科知识以及反思AI对相关学科的相互影响。\<br\>\<br\> • **CG4.1.3.4 在AI的设计和使用中具体化以人为本的考量：** 组织基于工具的AI反思活动，以具象化学生对AI对生活、工作和社会关系影响的理解。强调人类在AI生命周期关键步骤中的角色（例如，研究员、架构工程师、数据工程师、数据工作者、Beta测试员、伦理与安全监管员、人机交互专家和系统合规审计员）。引导学生深入熟悉与使用数据训练AI系统相关的主要伦理问题。 | • **基于实例理解AI的定义和范围：** 探究并试验AI工具的例子（例如，在医疗领域使用监督学习和图像分类进行癌症诊断，或在商业环境中使用自然语言处理和生成式AI进行自动会议纪要和文献综述撰写）。基于选定的例子，帮助学生理解什么是AI以及什么不是AI，以及日常生活中采用的主流AI技术类别和经济社会活动。引导学生探索AI生命周期的关键步骤；在适当时，为特定的AI系统绘制生命周期图并标注所使用的关键AI技术。\<br\>\<br\> • **从实例到抽象概念，再从概念到具体技术的螺旋式学习：** 使用选定的例子引导学生抽象出机器学习模型的训练过程，包括问题定义、数据收集、数据处理、训练、评估、部署以及基于测试和反馈的迭代。支持学生发展关于（并在可能的情况下，操作）AI技术使用的适龄知识和基本技能，涉及数据集、算法、AI架构、计算环境设置、功能和界面设计以及部署场景规划。\<br\>\<br\> • **创新AI工具和AI创新用法的案例分析：** 组织学生寻找潜在的创新AI工具和/或AI的创新用法；引导学生识别这些应用中使用的关键技术和主流AI类别。促进他们撰写一篇**议论文**或进行**口头答辩**，论述这些AI技术在多大程度上可以帮助人类在其个人实践、经济或商业模式或社会服务中进行创新，和/或特定AI技术可能对伦理原则和人类能动性构成的风险。\<br\>\<br\> • **巩固AI的多学科基础，特别侧重于数学：** 基于讲座和基于问题的探究，帮助学生掌握现代AI系统植根于数学，学习数据和算法需要扎实的数学基础和多学科知识体系。培养学生发展AI所需的基本数学和跨学科技能，包括代数、概率与统计、数据结构以及诸如**K-近邻算法、K-均值聚类、线性回归和CART/决策树**等算法的相关内容。培养学生在用于复杂数据表示和矩阵数学的**线性代数**，以及用于理解机器学习和神经网络的**反向传播**和**梯度下降**的**微积分**方面的高阶知识。支持学生巩固和扩展他们其他的多学科基础知识，尤其是在科学、技术和工程领域。 | • **无设备（Unplugged）学习环境**和资源，包括教科书、短文、工作表和印刷材料。\<br\>\<br\> • 介绍AI创新或工具的在线或下载的视频及其他媒体。\<br\>\<br\> • 本地可用的AI工具，包括安装在**智能手机**上的基本AI辅助应用。\<br\>\<br\> • 在线AI工具，例如图像和/或视频生成器、生成式AI模型以及社交媒体上的视频推荐。 |

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **人工智能系统设计** \<br\> **4.1.4 问题界定** \<br\>\<br\> • 学生应能理解\*\*“AI问题界定”**作为AI创新起点的重性。他们应能从法律、伦理和逻辑角度审视在特定情况下是否应使用AI；学生能在一个AI模型被训练以解决问题前，界定该问题的**边界、目标和约束\*\*；学生还应能获得构思和构建一个AI系统所需的知识和**项目规划技能**，包括评估不同AI技术的适宜性、界定数据需求，以及设计测试和反馈指标。 | • **CG4.1.4.1 为“何时不应使用AI”的批判性思维能力搭建脚手架：** 借鉴实例，引导学生发展批判性分析技能，以审视为何应使用或不应使用AI来应对某些现实世界的挑战（例如，提高机构生产力、社区的可持续发展，或人类决策的精确度和效率），并参考其对人类和环境的影响。明确在何时以及何种条件下，不能和/或不应将AI应用于某些问题（例如，当**非AI解决方案**能以更低的伦理风险和环境影响提供相同性能时，或当使用AI会削弱人类意识或操纵人类行为时）。\<br\>\<br\> • **CG4.1.4.2 支持获取和强化“界定待由AI系统解决的问题”的技能：** 基于一个模拟项目，支持学习和实践识别并界定一个应该且可能通过构建新AI模型来解决的问题的技能（例如，为少数族裔语言训练一个AI模型以更好地服务其社区，或为自动追踪目标区域的迁徙构建一个模型）。学生可以通过**制定问题陈述**来磨练其分析技能，这有助于避免在定义不清的问题上浪费时间和精力。\<br\>\<br\> • **CG4.1.4.3 发展评估AI系统对数据、算法和计算资源需求的技能：** 为学生提供机会，通过评估对数据、算法、编程语言、软件、计算能力和硬件的需求来发展规划技能；研究一个AI项目在数据可用性（考虑到法规和伦理限制）以及所需数据处理与工程、计算能力和硬件的总成本方面的可行性。 | • **模拟项目提案的评审：** 组织学生模拟一个项目提案的评审和论证过程。例如，提案可以是关于构建或选择一个AI系统。就项目中是否应使用AI来解决问题进行辩论，考虑的因素包括是否有足够的训练数据、伦理影响、环境影响，以及非AI解决方案是否能以更少的风险达到类似的效果。引导学生为评审勾勒出一个**核对清单（checkbox）**。\<br\>\<br\> • **模拟新AI系统设计的问题界定和论证：** 促进学生研究他们日常生活或社区中的问题（例如，在学校或志愿者工作中），并识别一个可能通过AI解决的问题（例如，为学校花园自动浇水，或帮助听力不佳的祖父母检测警报声）。支持学生通过预想关键特征（包括AI算法和数据集）来界定和定义问题，并产出相应的问题陈述。\<br\>\<br\> • **数据预处理实验室：** 使用一个基础数据集和一个现有AI模型的架构，组织关于基于不同版本的数据集来训练模型的实验（例如，一个分类神秘图像的挑战）。支持学生应用各种数据预处理技术，例如调整编码（如**数据增强、处理异常值和分析数据集偏斜/不平衡**）。支持他们基于修改后的数据集训练模型，并观察数据预处理如何影响模型的性能。 | • **无设备（Unplugged）学习环境**，包括工作表、纸质案例研究，以及AI系统设计的原型或计划的打印件。\<br\>\<br\> • 连接互联网的**数字设备**。\<br\>\<br\> • 选定的在线AI系统。 |

#### **4.2 水平2：应用 (Level 2: Apply)**

“应用”水平的总体目标是帮助学生构建一个**坚实且可迁移的AI概念知识结构**和相关技能体系，并习惯于应用以人为本的思维模式和伦理原则来指导对AI工具的评估、学习和实践。表3（原文后续表格）中的课程目标旨在指导规划一套核心的价值取向、实践性伦理原则和方法论知识，可用于定制课程模块和明确所有学生的**最终能力（exit competencies）**。

建议的教学方法旨在促进对概念知识的**基于问题的探究**和对操作技能的**基于任务的领会**，同时整合策略以保持学生对进一步学习的好奇心。在“应用”水平提供理想的学习环境涉及配置硬件、软件和应用程序，以支持AI操作和共同创造的实践，并考虑**开源方案**。

### **表3. 水平2：应用 (Apply) 的能力模块详解**

| **学生能力** | **课程目标**\<br\>（AI课程或学习项目应……） | **建议的教学方法**\<br\>（机构和教师可考虑并调整以下学习方法。） | **学习环境**\<br\>（可提供并调整以下学习环境。） |
| :--- | :--- | :--- | :--- |
| **以人为本的思维模式** \<br\> **4.2.1 人类问责** \<br\>\<br\> • 学生应能认识到**人类问责**是AI创造者和AI服务提供者的**法律义务**，并理解在设计和使用AI时他们应承担何种人类问责。他们还应培养一种意识，即当使用AI辅助影响人类的决策时，人类问责是一项法律和社会责任，并坚守在做出**高风险决策**时不应**将决定权让渡给AI**的原则。他们还应增强对那些声称AI可以篡夺人类思维和决策的**误导性说法**的判断力和心态韧性。 | • **CG4.2.1.1 建立“人类问责是AI创造者和服务提供者的一项法律义务”的观点：** 利用关于由人主导的AI生命周期的先备知识和真实世界的诉讼案例，引导学生理解人类AI创造者、服务提供者以及部署AI工具的机构，需对AI系统或服务可能导致的法律问题、违规和侵权行为负责。解释如何追究AI创造者、提供者和机构用户在安全事件、设计和训练AI中的伦理风险，以及滥用AI服务控制用户等方面的问责。引导学生理解他们在学习创造AI工具或设计AI系统时，自身应承担何种人类问责。\<br\>\<br\> • **CG4.2.1.2 形成“在使用AI对人类事务做决策时，人类问责是一项法律和社会责任”的理解：** 引导学生分析用于辅助决策的AI工具的能力。批判性质疑某些AI工具的真实能力，并**破除围绕AI所谓决策能力的炒作**。协助学生评估机构使用AI在复杂情况下对人类做决策的后果，例如，分析学生接受高等教育机会的资质，或决定求职者的可雇佣性。引导讨论为何在使用AI时，人类问责对于保障人权和人类尊严至关重要。促进学生理解为何在做出高风险决策时，我们不应使用AI取代人类，例如评估一个自然人的价值观、推断其情感或预测其资质。AI算法不应用于给学生评分（如COVID-19期间发生的情况）或决定大学录取。\<br\>\<br\> • **CG4.2.1.3 培养“人类问责需要个人能力来引导AI的有目的使用”的个人态度：** 引导学生质疑文献综述、写作和艺术创作的自动化如何可能削弱人类的思维过程和智力发展。引导学生讨论他们可以采取哪些具体行动，以保护自己和同伴免受使用AI产出或预测来篡夺人类思想、智力实践和持续能力提升的影响。 | • **为AI创造者和服务提供者撰写人类问责指南：** 促进学生扮演AI创造者和数据所有者的角色，并讨论他们在维护数据收集与处理的人类控制、训练AI模型、设计功能与界面、部署AI系统以及监控与反馈循环方面的关键法律和伦理问责。引导他们为自己关于AI系统设计、训练和迭代的学习撰写**自律准则**，要求AI创造者为保护数据所有者和AI用户的权利负责。\<br\>\<br\> • **调查AI辅助决策对人类的影响及AI法规中的补救途径：** 要求学生寻找由AI决定或极大影响人类决策的例子（例如，银行使用AI辅助评估系统来批准或拒绝学生贷款申请，或酒店使用分析系统根据客人的位置和预订时使用的设备来预测其社会经济背景）。促进学生揭示人类和AI在决策循环关键步骤中的角色，并检查决策中的人类问-责是否符合当地适用或国际法规（如欧盟《人工智能法案》）。\<br\>\<br\> • **有目的地使用AI的场景化实践：** 让学生参与一些活动，在其中有目的地使用AI工具来练习写作技巧，并培养他们的探究式学习、高阶思维和创造力。引导学生讨论在没有人类问责的情况下使用AI（例如，提交由AI生成的论文）如何可能削弱人类的智力发展。促使他们勾勒出具体行动，以保护自己和同伴免受使用AI产出或预测来篡夺思维过程的影响，并让他们洞察学生需要具备何种能力，才能引导AI的使用服务于人类能力的发展。 | • **无设备（Unplugged）和/或线下**学习环境和资源，包括纸质案例研究、角色扮演脚本、视频、工作表和翻转图表。\<br\>\<br\> • **在线AI工具**，例如学习管理系统、社交媒体平台和生成式AI平台。 |
